{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit 개선을 위한 L1, L2 규제의 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %autosave 0\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential  # class\n",
    "from tensorflow.keras.models import load_model  # model 사용\n",
    "from tensorflow.keras.layers import Dense       # 전결합\n",
    "from tensorflow.keras.layers import Dropout     # 특정 node를 사용안함.\n",
    "from tensorflow.keras.callbacks import EarlyStopping # 학습 자동 중지\n",
    "from tensorflow.keras import regularizers   # L1, L2 규제 적용\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold  # K 겹 교차 검증\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "font_name = font_manager.FontProperties(fname=\"C:/Windows/Fonts/malgunsl.ttf\").get_name()\n",
    "rc('font', family=font_name)           # 맑은 고딕 폰트 지정\n",
    "plt.rcParams[\"font.size\"] = 12         # 글자 크기\n",
    "# plt.rcParams[\"figure.figsize\"] = (10, 4) # 10:4의 그래프 비율\n",
    "plt.rcParams['axes.unicode_minus'] = False  # minus 부호는 unicode 적용시 한글이 깨짐으로 설정\n",
    "\n",
    "# Jupyter에게 matplotlib 그래프를 출력 영역에 표시할 것을 지시하는 명령\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(470, 18)\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('./Survival.csv', delimiter=\",\", dtype=np.float64)\n",
    "print(type(data))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(470, 17)\n",
      "(470,)\n"
     ]
    }
   ],
   "source": [
    "X = data[:, 0:17] # 0 ~ 16: 17개\n",
    "print(X.shape)\n",
    "Y = data[:, 17]   # 17: 1개\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "(43,)\n"
     ]
    }
   ],
   "source": [
    "# train_test_split 분할을 통한 훈련, 검증, 테스트 데이터의 분리\n",
    "seed = 0\n",
    "# 90%: 분할대기(x_train_all), 10%: 테스트(x_test)\n",
    "x_train_all, x_test, y_train_all, y_test = train_test_split(X, Y,\n",
    "                                                          stratify=Y,\n",
    "                                                          test_size=0.1,\n",
    "                                                          random_state=seed)\n",
    "# 약한 Overfit\n",
    "# 나머지 데이터 90%를 분할, 70%: 훈련(x_train), 30%: 검증(x_val)\n",
    "\n",
    "# 강한 Overfit\n",
    "# 나머지 데이터 90%를 분할, 90%: 훈련(x_train), 10%: 검증(x_val)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all,\n",
    "                                                  stratify=y_train_all,\n",
    "                                                  test_size=0.1,\n",
    "                                                  random_state=seed)\n",
    "\n",
    "print(y_val[0:100])\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1l2():\n",
    "    tf.random.set_seed(0)\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(128, input_dim=17, activation='linear')) \n",
    "    model.add(Dense(128, input_shape=(17, ), activation='relu',\n",
    "              kernel_regularizer=regularizers.l1_l2(l1=0.0001, l2=0.0001))) \n",
    "    model.add(Dense(64, activation='relu',\n",
    "              kernel_regularizer=regularizers.l1_l2(l1=0.0001, l2=0.0001)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid')) # 출력층, 입력: 15, 출력 1\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # 오차가 16번 증가되면 종료, Overfit 발생을위해 과도한 학습 진행\n",
    "    es = EarlyStopping(monitor='loss', patience=16, restore_best_weights=True)\n",
    "\n",
    "    # 학습\n",
    "    hist = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "                     epochs=1000, \n",
    "                     batch_size=2, callbacks=[es])\n",
    "    \n",
    "    fig, loss_ax = plt.subplots()\n",
    "    # plt.figure(figsize=(6,4)) # ERROR\n",
    "    fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "    acc_ax = loss_ax.twinx()  # 오른쪽 y 출 설정\n",
    "\n",
    "    # 왼쪽 y 축 설정\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    loss_ax.set_ylim([0.0, 1.0229]) # 값을 반영하여 변경\n",
    "\n",
    "    # 오른쪽 y 축 설정\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train accuracy')\n",
    "    acc_ax.plot(hist.history['val_accuracy'], 'g', label='val accuracy')\n",
    "    acc_ax.set_ylim([0.0, 1]) # 0.0, 1: 0 ~ 100 %, 정확도임으로 변경하지 않음\n",
    "\n",
    "    # 축 레이블 설정\n",
    "    loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "    loss_ax.set_ylabel('loss')   # 오차\n",
    "    acc_ax.set_ylabel('accuracy') # 정확도\n",
    "\n",
    "    loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "    acc_ax.legend(loc='lower left')  # 정확도 레이블 위치\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=1, verbose=0)\n",
    "    print('손실값:', test_loss, '/정확도:', (test_acc*100), '%')\n",
    "    \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout 사용의 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout 사용의 경우\n",
    "def dropout_use():\n",
    "    tf.random.set_seed(0)\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(128, input_dim=17, activation='linear')) # 첫번째 은닉층\n",
    "    model.add(Dense(128, input_shape=(17, ), activation='relu')) # 첫번째 은닉층\n",
    "    model.add(Dropout(0.2)) # 20% 비활성화, Node의 값을 0으로 변경\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2)) # 20% 비활성화, Node의 값을 0으로 변경\n",
    "\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid')) # 출력층, 입력: 15, 출력 1\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # 오차가 16번 증가되면 종료, Overfit 발생을위해 과도한 학습 진행\n",
    "    es = EarlyStopping(monitor='loss', patience=16, restore_best_weights=True)\n",
    "\n",
    "    # 학습\n",
    "    hist = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "                     epochs=1000, \n",
    "                     batch_size=2, callbacks=[es])\n",
    "    \n",
    "    fig, loss_ax = plt.subplots()\n",
    "    # plt.figure(figsize=(6,4)) # ERROR\n",
    "    fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "    acc_ax = loss_ax.twinx()  # 오른쪽 y 출 설정\n",
    "\n",
    "    # 왼쪽 y 축 설정\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    loss_ax.set_ylim([0.0, 1.0229]) # 값을 반영하여 변경\n",
    "\n",
    "    # 오른쪽 y 축 설정\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train accuracy')\n",
    "    acc_ax.plot(hist.history['val_accuracy'], 'g', label='val accuracy')\n",
    "    acc_ax.set_ylim([0.0, 1]) # 0.0, 1: 0 ~ 100 %, 정확도임으로 변경하지 않음\n",
    "\n",
    "    # 축 레이블 설정\n",
    "    loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "    loss_ax.set_ylabel('loss')   # 오차\n",
    "    acc_ax.set_ylabel('accuracy') # 정확도\n",
    "\n",
    "    loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "    acc_ax.legend(loc='lower left')  # 정확도 레이블 위치\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=1, verbose=0)\n",
    "    print('손실값:', test_loss, '/정확도:', (test_acc*100), '%')\n",
    "   \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1, L2, Dropout 사용의 경우\n",
    "def l1l2_dropout():\n",
    "    tf.random.set_seed(0)\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(128, input_dim=17, activation='linear')) \n",
    "    \n",
    "    model.add(Dense(128, input_shape=(17, ), activation='relu',\n",
    "              kernel_regularizer=regularizers.l1_l2(l1=0.0001, l2=0.0001)))\n",
    "    model.add(Dropout(0.1)) # 10% 비활성화, Node의 값을 0으로 변경\n",
    "\n",
    "    model.add(Dense(64, activation='relu',\n",
    "              kernel_regularizer=regularizers.l1_l2(l1=0.0001, l2=0.0001)))\n",
    "    model.add(Dropout(0.1)) # 10% 비활성화, Node의 값을 0으로 변경\n",
    "\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(15, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid')) # 출력층, 입력: 15, 출력 1\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    # 오차가 16번 증가되면 종료, Overfit 발생을위해 과도한 학습 진행\n",
    "    es = EarlyStopping(monitor='loss', patience=16, restore_best_weights=True)\n",
    "\n",
    "    # 학습\n",
    "    hist = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "                     epochs=1000, \n",
    "                     batch_size=2, callbacks=[es])\n",
    "    \n",
    "    fig, loss_ax = plt.subplots()\n",
    "    # plt.figure(figsize=(6,4)) # ERROR\n",
    "    fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "    acc_ax = loss_ax.twinx()  # 오른쪽 y 출 설정\n",
    "\n",
    "    # 왼쪽 y 축 설정\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    loss_ax.set_ylim([0.0, 1.0229]) # 값을 반영하여 변경\n",
    "\n",
    "    # 오른쪽 y 축 설정\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train accuracy')\n",
    "    acc_ax.plot(hist.history['val_accuracy'], 'g', label='val accuracy')\n",
    "    acc_ax.set_ylim([0.0, 1]) # 0.0, 1: 0 ~ 100 %, 정확도임으로 변경하지 않음\n",
    "\n",
    "    # 축 레이블 설정\n",
    "    loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "    loss_ax.set_ylabel('loss')   # 오차\n",
    "    acc_ax.set_ylabel('accuracy') # 정확도\n",
    "\n",
    "    loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "    acc_ax.legend(loc='lower left')  # 정확도 레이블 위치\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=1, verbose=0)\n",
    "    print('손실값:', test_loss, '/정확도:', (test_acc*100), '%')\n",
    "\n",
    "    return model, hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 15)                495       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 13,151\n",
      "Trainable params: 13,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "190/190 [==============================] - 1s 3ms/step - loss: 0.8545 - accuracy: 0.8260 - val_loss: 0.5608 - val_accuracy: 0.8605\n",
      "Epoch 2/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.7260 - accuracy: 0.7591 - val_loss: 0.5616 - val_accuracy: 0.8605\n",
      "Epoch 3/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.8588 - val_loss: 0.5055 - val_accuracy: 0.8605\n",
      "Epoch 4/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.8550 - val_loss: 0.4950 - val_accuracy: 0.8605\n",
      "Epoch 5/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.8091 - val_loss: 0.5165 - val_accuracy: 0.8605\n",
      "Epoch 6/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.8719 - val_loss: 0.5307 - val_accuracy: 0.8605\n",
      "Epoch 7/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.8281 - val_loss: 0.5917 - val_accuracy: 0.8605\n",
      "Epoch 8/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.5087 - accuracy: 0.8562 - val_loss: 0.5293 - val_accuracy: 0.8605\n",
      "Epoch 9/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.8337 - val_loss: 0.5116 - val_accuracy: 0.8605\n",
      "Epoch 10/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8654 - val_loss: 0.4801 - val_accuracy: 0.8605\n",
      "Epoch 11/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8841 - val_loss: 0.4838 - val_accuracy: 0.8605\n",
      "Epoch 12/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8603 - val_loss: 0.4761 - val_accuracy: 0.8605\n",
      "Epoch 13/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8543 - val_loss: 0.4854 - val_accuracy: 0.8605\n",
      "Epoch 14/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8542 - val_loss: 0.4741 - val_accuracy: 0.8605\n",
      "Epoch 15/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8441 - val_loss: 0.4664 - val_accuracy: 0.8605\n",
      "Epoch 16/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.8224 - val_loss: 0.4834 - val_accuracy: 0.8605\n",
      "Epoch 17/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8328 - val_loss: 0.5124 - val_accuracy: 0.8605\n",
      "Epoch 18/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4418 - accuracy: 0.8793 - val_loss: 0.4907 - val_accuracy: 0.8605\n",
      "Epoch 19/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4134 - accuracy: 0.8716 - val_loss: 0.4641 - val_accuracy: 0.8605\n",
      "Epoch 20/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8491 - val_loss: 0.4618 - val_accuracy: 0.8605\n",
      "Epoch 21/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.8498 - val_loss: 0.5029 - val_accuracy: 0.8605\n",
      "Epoch 22/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4511 - accuracy: 0.8562 - val_loss: 0.4552 - val_accuracy: 0.8605\n",
      "Epoch 23/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.8206 - val_loss: 0.4750 - val_accuracy: 0.8605\n",
      "Epoch 24/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.8259 - val_loss: 0.4578 - val_accuracy: 0.8605\n",
      "Epoch 25/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8834 - val_loss: 0.4685 - val_accuracy: 0.8605\n",
      "Epoch 26/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4480 - accuracy: 0.8608 - val_loss: 0.4644 - val_accuracy: 0.8605\n",
      "Epoch 27/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.8389 - val_loss: 0.4646 - val_accuracy: 0.8605\n",
      "Epoch 28/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.8412 - val_loss: 0.4540 - val_accuracy: 0.8605\n",
      "Epoch 29/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.8560 - val_loss: 0.4555 - val_accuracy: 0.8605\n",
      "Epoch 30/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8748 - val_loss: 0.4518 - val_accuracy: 0.8605\n",
      "Epoch 31/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.8389 - val_loss: 0.4568 - val_accuracy: 0.8605\n",
      "Epoch 32/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.8259 - val_loss: 0.4969 - val_accuracy: 0.8605\n",
      "Epoch 33/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8567 - val_loss: 0.4677 - val_accuracy: 0.8605\n",
      "Epoch 34/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4037 - accuracy: 0.8675 - val_loss: 0.4487 - val_accuracy: 0.8605\n",
      "Epoch 35/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.8604 - val_loss: 0.4464 - val_accuracy: 0.8605\n",
      "Epoch 36/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8546 - val_loss: 0.4442 - val_accuracy: 0.8605\n",
      "Epoch 37/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.8120 - val_loss: 0.5082 - val_accuracy: 0.8605\n",
      "Epoch 38/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4466 - accuracy: 0.8597 - val_loss: 0.4451 - val_accuracy: 0.8605\n",
      "Epoch 39/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.8344 - val_loss: 0.4417 - val_accuracy: 0.8605\n",
      "Epoch 40/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.8418 - val_loss: 0.4400 - val_accuracy: 0.8605\n",
      "Epoch 41/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4241 - accuracy: 0.8541 - val_loss: 0.4500 - val_accuracy: 0.8605\n",
      "Epoch 42/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8462 - val_loss: 0.4434 - val_accuracy: 0.8605\n",
      "Epoch 43/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.8262 - val_loss: 0.4422 - val_accuracy: 0.8605\n",
      "Epoch 44/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8356 - val_loss: 0.4355 - val_accuracy: 0.8605\n",
      "Epoch 45/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.8210 - val_loss: 0.4558 - val_accuracy: 0.8605\n",
      "Epoch 46/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8401 - val_loss: 0.4396 - val_accuracy: 0.8605\n",
      "Epoch 47/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4302 - accuracy: 0.8523 - val_loss: 0.4411 - val_accuracy: 0.8605\n",
      "Epoch 48/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.8329 - val_loss: 0.4404 - val_accuracy: 0.8605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8729 - val_loss: 0.4352 - val_accuracy: 0.8605\n",
      "Epoch 50/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4386 - accuracy: 0.8504 - val_loss: 0.4395 - val_accuracy: 0.8605\n",
      "Epoch 51/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.8326 - val_loss: 0.4358 - val_accuracy: 0.8605\n",
      "Epoch 52/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.8467 - val_loss: 0.4438 - val_accuracy: 0.8605\n",
      "Epoch 53/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.8191 - val_loss: 0.4329 - val_accuracy: 0.8605\n",
      "Epoch 54/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4046 - accuracy: 0.8639 - val_loss: 0.4329 - val_accuracy: 0.8605\n",
      "Epoch 55/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4248 - accuracy: 0.8544 - val_loss: 0.4343 - val_accuracy: 0.8605\n",
      "Epoch 56/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.8445 - val_loss: 0.4364 - val_accuracy: 0.8605\n",
      "Epoch 57/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.8514 - val_loss: 0.4293 - val_accuracy: 0.8605\n",
      "Epoch 58/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4091 - accuracy: 0.8678 - val_loss: 0.4330 - val_accuracy: 0.8605\n",
      "Epoch 59/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.8283 - val_loss: 0.4314 - val_accuracy: 0.8605\n",
      "Epoch 60/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4186 - accuracy: 0.8693 - val_loss: 0.4284 - val_accuracy: 0.8605\n",
      "Epoch 61/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8472 - val_loss: 0.4308 - val_accuracy: 0.8605\n",
      "Epoch 62/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.8253 - val_loss: 0.4274 - val_accuracy: 0.8605\n",
      "Epoch 63/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.8373 - val_loss: 0.4286 - val_accuracy: 0.8605\n",
      "Epoch 64/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.8561 - val_loss: 0.4283 - val_accuracy: 0.8605\n",
      "Epoch 65/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4129 - accuracy: 0.8576 - val_loss: 0.4322 - val_accuracy: 0.8605\n",
      "Epoch 66/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4819 - accuracy: 0.8167 - val_loss: 0.4540 - val_accuracy: 0.8605\n",
      "Epoch 67/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3869 - accuracy: 0.8675 - val_loss: 0.4271 - val_accuracy: 0.8605\n",
      "Epoch 68/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4729 - accuracy: 0.8223 - val_loss: 0.4497 - val_accuracy: 0.8605\n",
      "Epoch 69/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.8073 - val_loss: 0.4254 - val_accuracy: 0.8605\n",
      "Epoch 70/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4003 - accuracy: 0.8633 - val_loss: 0.4272 - val_accuracy: 0.8605\n",
      "Epoch 71/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8632 - val_loss: 0.4247 - val_accuracy: 0.8605\n",
      "Epoch 72/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.8481 - val_loss: 0.4266 - val_accuracy: 0.8605\n",
      "Epoch 73/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.8569 - val_loss: 0.4265 - val_accuracy: 0.8605\n",
      "Epoch 74/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4055 - accuracy: 0.8662 - val_loss: 0.4275 - val_accuracy: 0.8605\n",
      "Epoch 75/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3897 - accuracy: 0.8732 - val_loss: 0.4259 - val_accuracy: 0.8605\n",
      "Epoch 76/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4600 - accuracy: 0.8364 - val_loss: 0.4259 - val_accuracy: 0.8605\n",
      "Epoch 77/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8818 - val_loss: 0.4290 - val_accuracy: 0.8605\n",
      "Epoch 78/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.8332 - val_loss: 0.4248 - val_accuracy: 0.8605\n",
      "Epoch 79/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8375 - val_loss: 0.4241 - val_accuracy: 0.8605\n",
      "Epoch 80/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.8324 - val_loss: 0.4239 - val_accuracy: 0.8605\n",
      "Epoch 81/1000\n",
      "190/190 [==============================] - 0s 2ms/step - loss: 0.4016 - accuracy: 0.8680 - val_loss: 0.4221 - val_accuracy: 0.8605\n",
      "Epoch 82/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3979 - accuracy: 0.8693 - val_loss: 0.4212 - val_accuracy: 0.8605\n",
      "Epoch 83/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4226 - accuracy: 0.8501 - val_loss: 0.4220 - val_accuracy: 0.8605\n",
      "Epoch 84/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.8264 - val_loss: 0.4249 - val_accuracy: 0.8605\n",
      "Epoch 85/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.8259 - val_loss: 0.4324 - val_accuracy: 0.8605\n",
      "Epoch 86/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4856 - accuracy: 0.8218 - val_loss: 0.4244 - val_accuracy: 0.8605\n",
      "Epoch 87/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.3579 - accuracy: 0.8872 - val_loss: 0.4266 - val_accuracy: 0.8605\n",
      "Epoch 88/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.8409 - val_loss: 0.4203 - val_accuracy: 0.8605\n",
      "Epoch 89/1000\n",
      "190/190 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.8426 - val_loss: 0.4307 - val_accuracy: 0.8605\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "손실값: 0.4315280616283417 /정확도: 85.10638475418091 %\n"
     ]
    }
   ],
   "source": [
    "# model, hist = l1l2() \n",
    "\n",
    "# model, hist = dropout_use() \n",
    "\n",
    "model, hist = l1l2_dropout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}