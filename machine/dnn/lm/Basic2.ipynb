{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습률의 적용\n",
    "- 어떤수를 입력하면 100을 곱해서 출력하는 모델을 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %autosave 0 \n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# tensorflow 2.x에 내장된 Keras 사용\n",
    "from tensorflow.keras.models import Sequential  # class\n",
    "from tensorflow.keras.models import load_model  # model 파일 로딩\n",
    "from tensorflow.keras.layers import Dense       # 전결합층\n",
    "from tensorflow.keras.optimizers import Adam    # 가중치, bias 최적화\n",
    "from tensorflow.keras.utils import plot_model   # 네트워크 입출력 시각화\n",
    "\n",
    "# tensorflow 1.x, Keras가 독립적으로 설치된 경우\n",
    "# from keras.models import Sequential  # class\n",
    "# from keras.models import load_model  # model 사용 함수\n",
    "# from keras.layers import Dense       # class\n",
    "# from keras.optimizers import Adam    # 가중치, bias 최적화\n",
    "\n",
    "# tensorflow 1.2~\n",
    "# from tensorflow.keras.models import Sequential  # class\n",
    "# from tensorflow.keras.models import load_model  # model 파일 로딩\n",
    "# from tensorflow.keras.layers import Dense       # 전결합층\n",
    "# from tensorflow.keras.optimizers import Adam    # 가중치, bias 최적화\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import rc\n",
    "rc('font', family='Malgun Gothic')\n",
    "\n",
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "[ 100  200  300  400  500  600  700  800  900 1000 1100 1200 1300 1400\n",
      " 1500 1600 1700 1800 1900 2000]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEECAYAAADDOvgIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbrklEQVR4nO3de5Bc9Zne8e8DwkIwDqOAGMwUMQ6uYo2Rt9iZNRchmHHMpWQoE4ErCi7HiSlGhddkE7CyyI5NsOJIRouj7BLi1WZdW7uxPQVaI8i6vFykaRCwwkhWpSbmUsW6CMVoA7KIFEY7EQi9+aNPy0fdPT2XnnP6dM/zqZqiz6W7nzn09KvzO/3+WhGBmZlZ2gmtDmBmZsXj4mBmZjVcHMzMrIaLg5mZ1XBxMDOzGgtaHWAunHHGGXHuuee2OkZdhw4d4tRTT211jEkVPR8UP6PzNcf5mtNMvt27d/8qIpbU3RgRbf/T19cXRTUyMtLqCA0VPV9E8TM6X3OcrznN5AN2xSTvqx5WMjOzGi4OZmZWw8XBzMxquDiYmVkNFwczM6vh4mBm1oa27hlj2YbtjI4dZNmG7WzdMzanj59JcZDULWlYUknS05I+Iul8SdskPStpY2rfdZKeStZ/PFlXd18zMysXhrU/HmXswAQAYwcmWPvj0TktEFmdOZwC3BERA8B3gK8Cm4BbImIZcK6kiyUtB3oi4kpgNVApBDX7ZpTTzKztbHzsFSbee/+4dRPvvc/Gx16Zs+dQZPx9DpIuA24CLoqIwWTdKuAs4HRge0SMJOt3ApcDT1TvGxGbqh53CBgC6Onp6RseHs7095it8fFxurq6Wh1jUkXPB8XP6HzNcb6ZGx07eOx2zyJ4c+LX25b2njbtxxkcHNwdEf31tmU6fYakXspnDbcD/ym1aT/wMeBMYF9q/RGgJ9leve9xImIzsBmgv78/BgYG5jL6nCmVShQ1GxQ/HxQ/o/M1x/lm7usbth8bUrpz6RHuGy2/lfd2L+L2zw/MyXNkdkFa0nXAN4FbgbeB7tTmxZSLwsHkdsXRBvuamRmw5przWXTSicetW3TSiay55vw5e46sLkh/Arg+IlZHxP6ImAAWJmcSACuBbcAOykNOSLoAeKPBvmZmBtxwUS/rVy6lt3sRUD5jWL9yKTdc1DvFPacvq2Gla4HlkkrJ8uvAHcAWSYeBRyPiJUmvACsk7QDeoXxRmnr7ZpTTzKwt3XBRLzdc1EupVJqzoaS0TIpDRNwL3Ftn06VV+x0Fbqtz/xeq9zUzs/y4Cc7MzGq4OJiZWY2O+CY4M7N2s3XPGBsfe4W9ByY4u3sRa645f04vKDfLxcHMLGeV6S8qXc6V6S+AwhQIDyuZmeUsj+kvmuXiYGaWs70HJma0vhVcHMzMcnZ20rw23fWt4OJgZpazPKa/aJYvSJuZ5axy0dmfVjIzs+NUpr8oKg8rmZlZDRcHMzOr4WElM7NZKHqHc7NcHMzMZqgdOpyb5WElM7MZaocO52a5OJiZzVA7dDg3y8XBzGyG2qHDuVkuDmZmM9QOHc7NyuSCtKQlwL8CjgLfAf4ytfkfAJsi4g8kjQL7k/WbI+KHks4HHgBOBp6LiDVZZDQzm6126HBuVlafVroPeBU4JSLGgQEASScAPwW+n+z3ZkR8uuq+m4BbIuI1SQ9Jujgins8op5nZrBS9w7lZiohsHlgaAK6NiLtS624GzoiIP0iWH4+Iq1PbFwBPRMRgsrwKOCsiNtV5/CFgCKCnp6dveHg4k9+jWePj43R1dbU6xqSKng+Kn9H5muN8zWkm3+Dg4O6I6K+7MSIy+aF8trChat0IcGpy+1Tgb4CngQeBc4APAVtS+18F3DPVc/X19UVRjYyMtDpCQ0XPF1H8jM7XHOdrTjP5gF0xyftqbk1wki4GRiPiUFKUDgHnJduuojwU9UWgO3W3xcC+vDKa2fzR6R3Ozcrz00o3Aw9VFiSlL/XvA4iICWChpMr/oZXAttwSmtm8UOlwHjswQfDrDuete8ZaHa0w8iwOlwE/Sy1/VNKzkkYof6Kpcm3iDmCLpBLws4h4KceMZjYPzIcO52ZlNqwUESWglFr+7artrwDL6tzvBeDSrHKZmc2HDudmuQnOzOad+dDh3CwXBzObd+ZDh3OzPGW3mc0786HDuVkuDmY2L3V6h3OzPKxkZmY1XBzMzKyGi4OZmdXwNQcza0ue/iJbLg5m1nYq019Uupwr018ALhBzxMNKZtZ2PP1F9lwczKztePqL7Lk4mFnb8fQX2XNxMLO24+kvsucL0mbWdjz9RfZcHMysLXn6i2x5WMnMzGq4OJiZWQ0XBzNria17xli2YTujYwdZtmG7v7+5YDIpDpKWSPq2pHXJ8hckvSipJOnx1H7rJD2VfJf0x5N150valqzbmEU+M2utSofzWNKXUOlwdoEojqzOHO4DDgMnJcvdwNqIGIiIqwEkLQd6IuJKYDVQKQSbgFsiYhlwrqSLM8poZi3iDufiU0Rk88DSAHBtRNwl6RvAUxHxdGr7OmB7RIwkyzuBy4EnImIwWbcKOCsiNtV5/CFgCKCnp6dveHg4k9+jWePj43R1dbU6xqSKng+Kn9H5Zm507OCx2z2L4M1UY/PS3tNakGhyRTx+ac3kGxwc3B0R/fW25fVR1gXAvZLeA/48IjYDZwL7UvscAXqA/al1+4GP1XvA5DE2A/T398fAwEAGsZtXKpUoajYofj4ofkbnm7mvb9h+bEjpzqVHuG+0/FbU272I2z8/0MJktYp4/NKyypfLBemIuDsiLgGuAT6XXF84CCxO7XYUeJvyEFTFYo4vIGbWAdzhXHy5FAdJlTOUCeAdIIAdwE3J9guANyJiAlgoqdLZshLYlkdGM8vPDRf1sn7lUnqTuZB6uxexfuVSN7UVSF7DSuslfTJ5vocj4kVJLwMrJO2gXDBWJ/veAWyRdBh4NCJeyimjmeWo0uFcKpUKN5RkGRaHiCgBpeT2mjrbjwK31Vn/AnBpVrnMzGxqboIzM7MaLg5mZlbDs7Ka2axs3TPmKbM7mIuDmc1YZfqLSpdzZfoLwAWiQ3hYycxmzNNfdD4XBzObsb0HJma03tqPi4OZzdjZSfPadNdb+3FxMLMZ8/QXnc8XpM1sxioXnf1ppc7l4mBms1KZ/sI6k4eVzMyshouDmZnV8LCS2TzlDmdrxMXBbB5yh7NNxcNKZvOQO5xtKi4OZvOQO5xtKi4OZvOQO5xtKi4OZvOQO5xtKpkUB0lLJH1b0rpkeZWkkqRdktam9htN1pck3ZysO1/SNknPStqYRT6z+e6Gi3pZv3Ipvd2LENDbvYj1K5f6YrQdk9Wnle4DXgVOSZZfjYgBSScAz0n6rxGxD3gzIj5ddd9NwC0R8ZqkhyRdHBHPZ5TTbN5yh7M1oojI5oGlAeDaiLirav1PgJsj4qCkxyPi6tS2BcATETGYLK8CzoqITXUefwgYAujp6ekbHh7O5Pdo1vj4OF1dXa2OMami54PiZ3S+5jhfc5rJNzg4uDsi+utujIhMfoABYEPVui8DdyW3TwX+BngaeBA4B/gQsCW1/1XAPVM9V19fXxTVyMhIqyM0VPR8EcXP6HzNcb7mNJMP2BWTvK/m0gQn6YPARuDJiHggKUqHgPOS7VdRHor6ItCduutiYF8eGc3ajTucLUt5fVrpfuC7EbGlskJS+qMS+wAiYgJYKKnyCl8JbMspo1nbqHQ4jx2YIPh1h/PWPWOtjmYdIq/pM64DPiypsvwtYEzS94F3k5/bkm13AFskHQYejYiXcspo1jYadTj77MHmQmbFISJKQCm5ffokuy2rc78XgEuzymXWCdzhbFlzE5xZG3KHs2XNxcGsDbnD2bLmKbvN2pC/w9myNq3iIKmL8sdKBRARr2cZysym5g5ny9KUxUHSvcCngcpE7wHcnGUoMzNrremcOXwqIn4r8yRmZlYY07kg/bKkhZknMTOzwpjOmcNi4H9K2pUsR0R4WMmsSZ7+wopsOsXhy5mnMJtnKtNfVLqcK9NfAC4QVgiTDitJOiu5ubDOj5k1odH0F2ZF0OjMYRXlL95ZW7U+gC9lFchsPvD0F1Z0kxaHSL5gJyL+RW5pzOaJs7sXMVanEHj6CyuKKT+tJOkzkh6X9FzlJ49gZp3M019Y0U3ngvQ9lL9X4VbgYcoNcWbWBE9/YUU3neJwMCJel7QgIn4uaSNwb9bBzDqdp7+wIptOE9wTkk4H3pf0PeDEqe5gZmbtbTpnDj+IiP2SvgFcBLyccSYzM2ux6Zw5/Dcot0VHxM8j4u8yzmTWFrbuGWPZhu2Mjh1k2Ybt/v5m6yjTKQ47Jf17SSskXS3p6qnuIGmJpG9LWpcsny9pm6Rnk2sWlf3WSXoqWf/xRvuaFUmlw7nycdRKh7MLhHWK6RSHvwPeA36b8nc7XzKN+9wHHAZOSpY3AbdExDLgXEkXS1oO9ETElcBqYONk+07zdzHLjTucrdMpIhrvIA1ERCm1fHlEPDPlA0sDwLXAvwWeiIjBZP0q4CzgdGB7RIwk63cCl9fbt9KQV/X4Q8AQQE9PT9/w8PBUkVpifHycrq6uVseYVNHzQTEzjo4dPHa7ZxG8mepnW9p7WgsSTa6Ixy/N+ZrTTL7BwcHdEdFfb9ukF6QlCfgA8O8kXUX5W+BOBv6Q8oXp6VoC7E8t7wc+BpwJ7EutPwL0TLJvjYjYDGwG6O/vj4GBgRlEyk+pVKKo2aD4+aCYGb++YfuxIaU7lx7hvtHyn1Jv9yJu//xAC5PVKuLxS3O+5mSVr9Gw0mXAXwG/CTyW/PwF8KczfI4DQHdqeTHlonAwuV1xFHh7kn3NCsUdztbpGs2t9CwwKOlrEfEfqrdL+lBE/O1UTxARE5IWSuqNiDHK3db3AB8FbgJ2SLoAeKPBvmaFku5whnfodYezdZgp+xzqFYbED4BPTfN57gC2SDoMPBoRL0l6BVghaQfwDuWL0nX3neZzmOWq0uFcKpUKN5Rk1qzpNMFNRo02JhexS8ntFyh/0im9/ShwW5371exrZmb5ms5HWSfT+GNOZmbWtqYzZfcPJdX7l3zDMwczM2tf0xlW+iawWtLdwA+BH0XEe5S/Kc6sbW3dM+Yps80mMeWZQ0S8GhFrgH8M/CPgtaRQjGcdziwr6ekvAk9/YVZtOsNK50r6FvAI8DzwG8BLwIMZZzPLjKe/MGtsOhek/xB4JiKujogHIuKdiHgQeDXjbGaZ2Vvn+5sbrTebb6bT53D9JOt/d+7jmOXj7O5Fx6a/qF5vZs19lNWsbXn6C7PGmmmCM2tb6ekv/Gkls1ouDjZvVaa/MLNaHlYyM7MaLg5mZlbDw0rWttzhbJYdFwdrS5UO50ojW6XDGXCBMJsDHlaytuQOZ7NsuThYW3KHs1m2XBysLU3WyewOZ7O54eJgbckdzmbZyu2CtKSvADelVl0I/GtgLfAW8G5EXJ3suw64Isk3FBG/yCuntQd3OJtlK7fiEBH3A/cDSLoR+AjQDayNiEcq+0laDvRExJWSLgQ2Aivyymntwx3OZtlRRL5fBS3pBOBJym/4a4CnIuLp1PZ1wPaIGEmWd0bEJXUeZwgYAujp6ekbHh7OI/6MjY+P09XV1eoYkyp6Pih+RudrjvM1p5l8g4ODuyOiv+7GiMj1h/I3yq1Nbt8D7AR2UB4+Avgj4MLU/s8AJzR6zL6+viiqkZGRVkdoqOj5Ioqf0fma43zNaSYfsCsmeV9tRRPcl4BbACLibuBuSacAj0h6FjgILE7tfzQijuYf07LmDmez4sr100qSTgdOjoi3kuVKcZoA3gGC8lnETcn2C4A38sxo+fB3OJsVW94fZb0C+OvU8npJT1EeOnouIl4EfgJ8QNIO4PeB38s5o+XAHc5mxZbrsFJEPAw8nFpeU2efo8Bteeay/LnD2azY3ARnLeEOZ7Nic3GwlnCHs1mxecpuawl3OJsVm4uDtYw7nM2Ky8NKZmZWw8XBzMxquDiYmVkNX3OwWfP0F2ady8XBZqUy/UWly7ky/QXgAmHWATysZLPi6S/MOpuLg82Kp78w62wuDjYrnv7CrLO5ONisePoLs87mC9I2K57+wqyzuTjYrHn6C7PO5WElMzOr4eJgZmY1XBzmqa17xli2YTujYwdZtmG7v7vZzI6T6zUHSaPA/mRxM7AbeAA4mfJ3SK9J9ltH+fumFwBDEfGLPHN2uuO6m89xd7OZ1cr7gvSbEfHpyoKknwK3RMRrkh6SdDHwAaAnIq6UdCGwEViRc86O1qi72cXBzAAUEfk9mfR4RFyd3F4APBERg8nyKuAs4HRge0SMJOt3RsQldR5rCBgC6Onp6RseHs7pt5iZ8fFxurq6Wh3jOKNjB4/d7lkEb6aampf2ntaCRI0V8RimOV9znK85zeQbHBzcHRH99bblduYg6VTgPElPA/8buJNfDzGR3P4YcCawL7X+iKQTIuJo+vEiYjPloSn6+/tjYGAgw/SzVyqVKFq2r2/YzlgyzcWdS49w32j5ZdDbvYjbPz/QwmT1FfEYpjlfc5yvOVnly+2CdEQciojzIuIK4I+B7wLdqV0WUy4KB5PbFUerC4M1x93NZjaV3IqDpPS70T4ggIWSKoPcK4FtwA7gpuQ+FwBv5JVxvrjhol7Wr1xKbzIPUm/3ItavXOrrDWZ2TJ4XpD8q6fvAu8nPbZSvL2yRdBh4NCJekvQKsELSDuAdYHWOGeeNSndzqVQq5FCSmbVWbsUhIl4BllWt/iVwadV+RykXDjMzaxE3wZmZWQ0XBzMzq+FZWdvU1j1jni7bzDLj4tCGjpv+Ak9/YWZzz8NKbajR9BdmZnPBxaEN7T0wMaP1ZmYz5eLQhs5Omtemu97MbKZcHNqQp78ws6z5gnQbqlx09qeVzCwrLg5tqjL9hZlZFjysZGZmNVwczMyshoeVWsQdzmZWZC4OLeAOZzMrOg8rtYA7nM2s6FwcWsAdzmZWdC4OLeAOZzMrOheHFnCHs5kVXW4XpCV1A98DzqJclL4IXA6sBd4C3o2Iq5N91wFXJPmGIuIXeeXMgzuczazo8vy00inAHRGxV9JngK8CLwNrI+KRyk6SlgM9EXGlpAuBjcCKHHPmwh3OZlZkioj8n1S6DLgBeAd4KiKeTm1bB2yPiJFkeWdEXFLnMYaAIYCenp6+4eHhPKLP2Pj4OF1dXa2OMami54PiZ3S+5jhfc5rJNzg4uDsi+utujIhcf4Be4MfA2cA9wE5gB+XhI4A/Ai5M7f8McEKjx+zr64uiGhkZaXWEhoqeL6L4GZ2vOc7XnGbyAbtikvfVXJvgJF0HXA/cGhH7gbuBuyWdAjwi6VngILA4dbejEXE0z5xmZvNdnhekPwFcHxGrU+sWRMQRYILyEFNQPou4Cdgh6QLgjbwyzoSnvzCzTpbnmcO1wHJJpWT5deBNSZ9McjwcES9KehlYIWkH5YKxuu6jtZCnvzCzTpdbcYiIe4F7p7HfUeC27BPNXqPpL1wczKwTuAluFjz9hZl1OheHWfD0F2bW6VwcZsHTX5hZp/P3OcyCp78ws07n4jBLnv7CzDqZh5XMzKyGi4OZmdWYt8NK7nA2M5vcvCwO7nA2M2tsXg4rNepwNjOzeVoc3OFsZtbYvCwO7nA2M2tsXhYHdzibmTU2Ly9Iu8PZzKyxeVkcwB3OZmaNzMthJTMza8zFwczMarg4mJlZDRcHMzOr4eJgZmY1FBGtztA0SfuA/9XqHJM4A/hVq0M0UPR8UPyMztcc52tOM/k+HBFL6m3oiOJQZJJ2RUR/q3NMpuj5oPgZna85ztecrPJ5WMnMzGq4OJiZWQ0Xh+xtbnWAKRQ9HxQ/o/M1x/mak0k+X3MwM7MaPnMwM7MaLg5mZlbDxWGOSOqWNCypJOlpSR9JbTtH0t5kW0nSBS3MOZrKcXNqfZekHyXZt0r6eznn+koqV0nSr1LbWnb8JC2R9G1J65Ll8yVtk/SspI119r9B0g5Jz0v6Jy3Ityo5Rrskra2z/59Iei7Z594W5PuCpBeT53+8zv4tO37J30D6NfhLSf+yav+8j1/N+0pur8GI8M8c/ABnA2cntz8D/OfUtqXAf2x1xiTLk5Os/wZwc3L7d4Dfa2HGG4GvFuH4AX8GfBPYkCz/FDg3uf0QcHFq31OBZ4CFye09wMk55+tP/nsCsBNYUrX/XwCntfD43Q58dpJ9W378UutPAB4Dulp8/GreV/J6DfrMYY5ExN6I2Jss/h/gUGpzd7KuCI5Osv5TlF9oUP4DuDSfOMeTdALl4nR/anU3LTp+EfHPgKcBJC2g/If2WrK5+jhdAmyLiMMRcQh4HviNvPIly7uS/x4F9gPvVt3lg8D/zTJTo3w0/n/Z8uOXsgr4SUSMV63P+/hVv68cJqfXoIvDHJPUC3wV2JRafQpwY3IauEnSSS3KdipwXnJ6+qCkc1KbF0bEe8nt/cDi/BMC8FngiYj4f6l1hTh+wBLKx6ai+jidCexrsD03kr4M7IiIg1WbAihJelzS8hZEWwDcmwx7DFVtK8zxA24F/qTO+pYcv9T7yn3k9Bp0cZhDkq6jfIp6a6raExGPRcRvAsuBdyi/8HIXEYci4ryIuAL4Y8ovtIqjyb/aofxi2lfzAPn4ElV/lEU5fsAByv/yrag+Tgc5/g8x9+Mo6YOSvge8FREbqrdHxDURcSVwC+UhilxFxN0RcQlwDfA5SR9PbW758QOQdDEwmvzL+zitOH7p9xXgbXJ6Dbo4zBFJnwCuj4jVEbG/atsCOO5UvyUknZharH7BPE/5X+1QHvN/MpdQKZJOp3zK/FbV+kIcv4iYABYm/4oDWAlsS+3yM+BaSSdJOgW4EHg555j3A9+NiC31NlaOJeUhivfq7ZOl1PNPUC706UarIhw/gJv59RDrcfI+ftXvK3m+Buftd0hn4FpguaRSsvw68LeUL/TeKOl3gPeB14Dq0+m8fFTS9ymPQ78L3CbpO0nG9cCfS/pd4FXK4/55uwL468pCKltRjh/AHcAWSYeBRyPiJUmfBM6LiB9J+lPKFwQngLsj4kjO+a4DPiypsvwtYLySD/ir5A3uROBrOWcDWJ8crwXAwxHxYsGOH8BlwL+pLKTzkf/xq/e+kstr0B3SZmZWw8NKZmZWw8XBzMxquDiYmVkNFwczM6vh4mBmZjVcHMzMrIaLg9kckTQww/1/P5skZs1zn4PZHJG0M5kaIr1O4T8ya0M+czCbBklrJN2a3P4zSb9Vtf0h4IJk3v2/n/z3LuAnyfZhSSOSdkr6h8m6ncl//7mkByT99+S7Dm7K97czq+XiYDY93wU+K+lG4JcR8fP0xoj4HPBiRAxExNvJ6p9HxIrk9u0RMQj8F+Cf1nn87oi4HhgA1mTyG5jNgOdWMpuGiHhf0v3ADyh/Act0PAcg6Uzgm5LGk/vurbPvjuR53krNi2TWMj5zMJuGZEbbIeBu4CuT7Fb9PROVCc++ADwbEXcB/2OS+8Ykt81awsXBbHq+ATwUEfcDA1XfQ1Dxy+RLbKq/XOVJ4GuS/hL4UNZBzeaCP61kZmY1fM3BbIYkXQvclVq1L7kgbdYxfOZgZmY1fM3BzMxquDiYmVkNFwczM6vh4mBmZjX+P0JGFPfXNJpCAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = np.array([i for i in range(1, 21)]) # 데이터\n",
    "print(x_train) # 독립 변수\n",
    "y_train = np.array([i*100 for i in range(1, 21)]) # 정답, 실제값, Target\n",
    "print(y_train) # 종속 변수: 독립변수 * 100\n",
    "\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.xlabel('x_train')\n",
    "plt.ylabel('y_train')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 73462974.0074 - val_loss: 38818380.0000\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 30323418.6765 - val_loss: 840789.5625\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3278703.3732 - val_loss: 1775097.8750\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2880556.2426 - val_loss: 1559630.1250\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115692.5039 - val_loss: 143293.8750\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31058.9870 - val_loss: 57083.0352\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 22143.8035 - val_loss: 24490.9824\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 18426.6094 - val_loss: 7757.8618\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8318.3624 - val_loss: 11892.5527\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4120.7618 - val_loss: 5383.3652\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1048.6109 - val_loss: 3306.6489\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1229.1399 - val_loss: 19641.4141\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6347.5020 - val_loss: 43900.0156\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3513.8923 - val_loss: 2689.8494\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 403.3170 - val_loss: 6.3268\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 53.4800 - val_loss: 1.8374\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.6389 - val_loss: 40.2706\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.7931 - val_loss: 13.0461\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.5373 - val_loss: 35.3422\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.0279 - val_loss: 55.5208\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 11.6445 - val_loss: 22.6927\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.5318 - val_loss: 2.9173\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3334 - val_loss: 3.2236e-04\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1561 - val_loss: 0.9932\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1369 - val_loss: 0.0013\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0011 - val_loss: 0.0118\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.7542e-04 - val_loss: 0.0074\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0249\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0141\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0086\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0315\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0019\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 3.5097e-04\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.3547e-05 - val_loss: 1.5549e-04\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.5528e-05 - val_loss: 1.1022e-04\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9668e-05 - val_loss: 0.0013\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.9059e-04 - val_loss: 2.5428e-04\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.1502e-04 - val_loss: 0.0010\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.5082e-04 - val_loss: 1.4130e-05\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0015 - val_loss: 2.9739e-04\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0062\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0378\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0381 - val_loss: 0.2506\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4843 - val_loss: 31.9905\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.9338 - val_loss: 0.0670\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1420 - val_loss: 5.6241\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2464 - val_loss: 0.9460\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5649 - val_loss: 4.4724\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2089 - val_loss: 4.3203\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1073 - val_loss: 99.5741\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.6438 - val_loss: 4.2197\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.8654 - val_loss: 5.9595\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3856 - val_loss: 6.1622\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.3141 - val_loss: 14.4463\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.8911 - val_loss: 52.6306\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 63.9246 - val_loss: 393.3207\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 273.7619 - val_loss: 158.1092\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35.3229 - val_loss: 173.2182\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 128.5862 - val_loss: 1564.3179\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 615.0288 - val_loss: 1004.2977\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 135.6168 - val_loss: 3232.9893\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 3274.9844 - val_loss: 1177.2767\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 459.3038 - val_loss: 69.2964\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2866.1203 - val_loss: 11906.8896\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51533.7593 - val_loss: 17702.7656\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 17882.6664 - val_loss: 26803.7422\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 218395.3604 - val_loss: 12001104.0000\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1897698.0404 - val_loss: 334812.6250\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37787.8133 - val_loss: 552252.9375\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30155.3556 - val_loss: 29703.1992\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 23536.2323 - val_loss: 45766.5625\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 18809.8590 - val_loss: 154414.2969\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 40165.2275 - val_loss: 36145.4844\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 198360.3770 - val_loss: 860344.3125\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 188321.9513 - val_loss: 168472.4375\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 42254.1296 - val_loss: 11350.0469\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16260.3128 - val_loss: 23425.4297\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4859.5928 - val_loss: 18322.6719\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1663.1558 - val_loss: 1732.4390\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 334.6095 - val_loss: 520.0092\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 100.2756 - val_loss: 45.1457\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.1696 - val_loss: 8.5410\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7958 - val_loss: 1.4466\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.3447 - val_loss: 0.1037\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0379 - val_loss: 0.0567\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0126 - val_loss: 0.0202\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3433e-04 - val_loss: 2.3581e-06\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.0813e-05 - val_loss: 2.2512e-05\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.5290e-05 - val_loss: 8.7048e-04\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2912e-04 - val_loss: 3.0149e-04\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.5910e-05 - val_loss: 4.7721e-05\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1093e-04 - val_loss: 2.5203e-04\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.9868e-04 - val_loss: 3.4856e-04\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.1727e-05 - val_loss: 3.8119e-04\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7915e-05 - val_loss: 2.1560e-04\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.9766e-05 - val_loss: 4.1474e-04\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.3545e-05 - val_loss: 4.7404e-05\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0008e-05 - val_loss: 9.9353e-06\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2653e-06 - val_loss: 1.4901e-08\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.9020e-07 - val_loss: 2.6077e-08\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1919e-08 - val_loss: 4.8429e-08\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.3263e-09 - val_loss: 1.1176e-08\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.1286e-10 - val_loss: 1.1176e-08\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.9711e-10 - val_loss: 1.1176e-08\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.8335e-10 - val_loss: 1.1176e-08\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.2096e-10 - val_loss: 1.1176e-08\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5457e-10 - val_loss: 1.1176e-08\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.5045e-10 - val_loss: 1.1176e-08\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.0489e-10 - val_loss: 1.1176e-08\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.2593e-10 - val_loss: 1.1176e-08\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.2830e-10 - val_loss: 1.1176e-08\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.0637e-10 - val_loss: 1.1176e-08\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.0644e-10 - val_loss: 1.1176e-08\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0254e-10 - val_loss: 1.1176e-08\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.7069e-10 - val_loss: 1.1176e-08\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.8129e-10 - val_loss: 1.1176e-08\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3789e-10 - val_loss: 1.1176e-08\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.2774e-10 - val_loss: 1.1176e-08\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0804e-10 - val_loss: 1.1176e-08\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2823e-10 - val_loss: 1.1176e-08\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.4302e-10 - val_loss: 1.1176e-08\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2988e-10 - val_loss: 1.1176e-08\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.5161e-10 - val_loss: 1.1176e-08\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2694e-10 - val_loss: 1.1176e-08\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8487e-10 - val_loss: 1.1176e-08\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.4693e-10 - val_loss: 1.1176e-08\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.1657e-10 - val_loss: 1.1176e-08\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.4331e-10 - val_loss: 1.1176e-08\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.5154e-10 - val_loss: 7.4506e-09\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9720e-10 - val_loss: 7.4506e-09\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8308e-10 - val_loss: 7.4506e-09\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.1942e-10 - val_loss: 7.4506e-09\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0708e-10 - val_loss: 7.4506e-09\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6807e-09 - val_loss: 7.4506e-09\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7167e-10 - val_loss: 7.4506e-09\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3574e-10 - val_loss: 7.4506e-09\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.6935e-10 - val_loss: 7.4506e-09\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.4095e-10 - val_loss: 7.4506e-09\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5413e-10 - val_loss: 7.4506e-09\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.5017e-10 - val_loss: 7.4506e-09\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6163e-10 - val_loss: 7.4506e-09\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.3789e-10 - val_loss: 7.4506e-09\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.5094e-10 - val_loss: 7.4506e-09\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.7326e-10 - val_loss: 7.4506e-09\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 9.8662e-10 - val_loss: 7.4506e-09\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0191e-10 - val_loss: 7.4506e-09\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.7791e-10 - val_loss: 7.4506e-09\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8021e-10 - val_loss: 7.4506e-09\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4728e-10 - val_loss: 7.4506e-09\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.8882e-10 - val_loss: 7.4506e-09\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6789e-10 - val_loss: 7.4506e-09\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2590e-10 - val_loss: 7.4506e-09\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3440e-10 - val_loss: 7.4506e-09\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0962e-10 - val_loss: 7.4506e-09\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.6957e-11 - val_loss: 7.4506e-09\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.5261e-09 - val_loss: 7.4506e-09\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.2976e-10 - val_loss: 1.1176e-08\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.2085e-09 - val_loss: 7.4506e-09\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.7055e-08 - val_loss: 1.9372e-07\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.2948e-08 - val_loss: 4.8429e-08\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.0700e-09 - val_loss: 1.1176e-08\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.3990e-09 - val_loss: 2.2352e-08\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8736e-08 - val_loss: 5.5134e-07\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0499e-07 - val_loss: 6.7055e-08\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.3265e-08 - val_loss: 7.4506e-09\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.2062e-09 - val_loss: 7.4506e-08\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.3607e-08 - val_loss: 3.3528e-08\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8796e-07 - val_loss: 2.2352e-08\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.7504e-08 - val_loss: 2.2352e-08\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5703e-08 - val_loss: 2.9802e-08\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.9093e-09 - val_loss: 1.4901e-08\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7419e-08 - val_loss: 7.4506e-08\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.1853e-08 - val_loss: 8.5682e-08\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0103e-07 - val_loss: 2.4587e-07\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9955e-08 - val_loss: 7.4506e-09\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.8721e-08 - val_loss: 3.7253e-09\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.5497e-09 - val_loss: 5.2154e-08\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.4322e-09 - val_loss: 9.6858e-08\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0514e-08 - val_loss: 1.8626e-08\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.2730e-08 - val_loss: 1.1660e-06\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2352e-07 - val_loss: 8.5682e-08\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.5802e-08 - val_loss: 6.7055e-08\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.1178e-09 - val_loss: 2.2352e-08\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.9724e-09 - val_loss: 3.7253e-09\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3410e-09 - val_loss: 3.7253e-09\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.0281e-09 - val_loss: 1.1176e-08\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.4892e-09 - val_loss: 1.4901e-08\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6359e-08 - val_loss: 1.4901e-08\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8604e-08 - val_loss: 1.4156e-07\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.7869e-08 - val_loss: 1.3486e-06\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.2727e-07 - val_loss: 2.5332e-07\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0641e-07 - val_loss: 6.9067e-06\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0005e-06 - val_loss: 8.4937e-07\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.7023e-07 - val_loss: 1.0952e-06\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 9.3173e-07 - val_loss: 1.6529e-05\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1087e-06 - val_loss: 4.8429e-06\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4037e-06 - val_loss: 2.2460e-05\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0338e-05 - val_loss: 2.0899e-06\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 9.0646e-06 - val_loss: 5.6848e-06\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.3728e-06 - val_loss: 9.9130e-06\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.9769e-07 - val_loss: 1.1176e-08\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.6839e-08 - val_loss: 4.6194e-07\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.0657e-08 - val_loss: 3.7253e-08\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.2030e-08 - val_loss: 2.1234e-07\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7439e-08 - val_loss: 4.8429e-08\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.0113e-08 - val_loss: 3.7253e-09\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.3165e-08 - val_loss: 1.2852e-06\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.2831e-07 - val_loss: 6.8918e-07\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0334e-07 - val_loss: 9.3356e-06\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.9296e-06 - val_loss: 1.2144e-05\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 6.4671e-06 - val_loss: 1.9100e-05\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.9692e-06 - val_loss: 3.8429e-04\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9441e-04 - val_loss: 6.5341e-04\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.1132e-04 - val_loss: 0.0012\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0714e-04 - val_loss: 0.0015\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 1.4038e-04\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0012 - val_loss: 0.0340\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0320 - val_loss: 0.0538\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0700\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0057 - val_loss: 6.1268e-04\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.5484e-04 - val_loss: 0.0023\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.6949e-04 - val_loss: 0.0224\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0028 - val_loss: 2.2491e-04\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0029 - val_loss: 0.1279\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0790 - val_loss: 2.5784\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.6598 - val_loss: 81.0955\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 14.5216 - val_loss: 202.7354\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 15.1653 - val_loss: 69.7969\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 40.2606 - val_loss: 0.1494\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 24.3488 - val_loss: 48.8823\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 33.8795 - val_loss: 155.1966\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 39.5004 - val_loss: 49.0653\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 154.7208 - val_loss: 2142.6584\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1754.5458 - val_loss: 34158.7969\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4820.3050 - val_loss: 12572.1484\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9689.5467 - val_loss: 5282.9902\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3425.2490 - val_loss: 31660.0742\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 18472.3202 - val_loss: 609794.7500\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 902945.2241 - val_loss: 798224.3125\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9147171283.4044 - val_loss: 2260220416.0000\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1393727638.5882 - val_loss: 783858368.0000\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 169887657.4118 - val_loss: 1926935.1250\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 29543754.3382 - val_loss: 22467200.0000\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3494432.9118 - val_loss: 3655702.0000\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 869340.8879 - val_loss: 153023.7500\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 63735.7344 - val_loss: 1666.1893\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 15342.0409 - val_loss: 13408.6680\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5561.7513 - val_loss: 13186.3340\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1827.0688 - val_loss: 39.0191\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 932.6587 - val_loss: 110.7987\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 504.3689 - val_loss: 74.4262\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 152.6976 - val_loss: 100.9791\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 34.2325 - val_loss: 145.1226\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 22.5952 - val_loss: 0.7936\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.2478 - val_loss: 0.6710\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.5586 - val_loss: 8.7410\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.6506 - val_loss: 14.0911\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7386 - val_loss: 0.0423\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2525 - val_loss: 0.0394\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0824 - val_loss: 3.7192e-04\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0288 - val_loss: 0.0232\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0032 - val_loss: 0.0096\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.7636e-04 - val_loss: 1.4737e-05\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.1811e-05 - val_loss: 5.2154e-06\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4141e-05 - val_loss: 9.0823e-05\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1836e-05 - val_loss: 1.1459e-05\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4582e-05 - val_loss: 1.7717e-05\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2142e-05 - val_loss: 5.2914e-05\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.5755e-06 - val_loss: 1.3664e-05\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.5170e-05 - val_loss: 1.6361e-05\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3258e-05 - val_loss: 4.6045e-05\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.1491e-05 - val_loss: 1.8150e-05\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0603e-05 - val_loss: 1.6361e-05\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1537e-05 - val_loss: 1.2085e-05\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0557e-05 - val_loss: 3.0756e-05\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.8686e-06 - val_loss: 2.8312e-05\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.4255e-06 - val_loss: 3.1739e-05\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.0574e-06 - val_loss: 1.1861e-05\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.9540e-06 - val_loss: 2.9847e-05\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0063e-05 - val_loss: 2.8133e-05\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1912e-05 - val_loss: 2.9385e-05\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3547e-05 - val_loss: 2.6941e-05\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.4967e-06 - val_loss: 2.1517e-05\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4324e-05 - val_loss: 2.2665e-05\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.5303e-06 - val_loss: 2.1130e-05\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.9346e-06 - val_loss: 1.9103e-05\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 9.3123e-06 - val_loss: 1.7196e-05\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0746e-05 - val_loss: 1.5408e-05\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.8056e-06 - val_loss: 1.8984e-05\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.4066e-06 - val_loss: 1.7852e-05\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.9756e-06 - val_loss: 1.1712e-05\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0605e-05 - val_loss: 1.0222e-05\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1789e-05 - val_loss: 1.6302e-05\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0650e-05 - val_loss: 8.0764e-06\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0484e-05 - val_loss: 1.2726e-05\n"
     ]
    }
   ],
   "source": [
    "### 학습률 10 지정\n",
    "model = Sequential() # 컨테이너 객체 생성\n",
    "# Dense: 전결합층, 1: 뉴런(노드)의 수, input_dim=1: 입력데이터의 가지수\n",
    "# activation='linear': 활성화 함수 입력 -> 출력\n",
    "model.add(Dense(10, input_dim=1, activation='linear'))\n",
    "model.add(Dense(1, activation='linear')) # 입력값은 이전 Layer의 노드수 10개\n",
    "# optimizer='adam': 오차역전파 알고리즘, loss='mse': 평균제곱오차\n",
    "model.compile(optimizer=Adam(lr=10), loss='mse')\n",
    "model.summary() # 네트워크 확인, Param: 가중치, 편향, 100만개이상이면 GPU 권장\n",
    "# Dense: 전결합층 기반의 네트워크\n",
    "# Output Shape: (None, 1) 출력은 2차원의 형태임, 컬럼이 1개임\n",
    "# None: 입력값에 따라 출력값의 갯수가 결정된으로 출력값은 가변적임.\n",
    "hist = model.fit(x_train, y_train, validation_split=0.2, shuffle=True,\n",
    "                epochs=300, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "# plt.figure(figsize=(6,4)) # ERROR\n",
    "fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "# 왼쪽 y 축 설정\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 10.0000]) # 값을 반영하여 변경 ★\n",
    "\n",
    "# 축 레이블 설정\n",
    "loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "loss_ax.set_ylabel('loss')   # 오차\n",
    "\n",
    "loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "\n",
    "plt.show()\n",
    "# train loss: 하강하면 훈련이 정상적으로 진행되고 있음\n",
    "# val loss: 하강하면 훈련되지 않은 데이터를 대상으로 한 테스트도 정상적으로 진행됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 462081.4995 - val_loss: 2054219.0000\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 340798.3487 - val_loss: 69314.2578\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7861.3834 - val_loss: 20378.7383\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7212.6326 - val_loss: 23625.1133\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3009.6333 - val_loss: 664.0443\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1759.4063 - val_loss: 4686.1372\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1912.5329 - val_loss: 2238.4246\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 910.0080 - val_loss: 3235.6616\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1037.4148 - val_loss: 1430.9810\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 666.7486 - val_loss: 2028.2117\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 723.0857 - val_loss: 2164.8296\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 797.4343 - val_loss: 1768.9858\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 443.3964 - val_loss: 822.3770\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 298.1598 - val_loss: 1576.8945\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 525.2965 - val_loss: 658.0022\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 211.9119 - val_loss: 1058.0537\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 313.6621 - val_loss: 303.9542\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 145.8172 - val_loss: 190.2737\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 138.7098 - val_loss: 414.1816\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 126.4120 - val_loss: 122.4283\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 140.0369 - val_loss: 496.5249\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 118.0111 - val_loss: 9.9913\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 89.0422 - val_loss: 149.4039\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 32.7260 - val_loss: 32.9390\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 56.6043 - val_loss: 75.4928\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 47.8410 - val_loss: 80.4362\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 22.9477 - val_loss: 31.4581\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 18.9652 - val_loss: 19.1431\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.3716 - val_loss: 11.6627\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 9.2152 - val_loss: 19.0736\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8.1343 - val_loss: 0.5388\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.5619 - val_loss: 0.1095\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.5322 - val_loss: 1.3114\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.0921 - val_loss: 2.1217\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6941 - val_loss: 0.0209\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1341 - val_loss: 0.9398\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4141 - val_loss: 2.6404\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5189 - val_loss: 0.3016\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2489 - val_loss: 0.0577\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1998 - val_loss: 0.1063\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1155 - val_loss: 0.0214\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0475 - val_loss: 0.0045\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0603 - val_loss: 0.0915\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0369\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0164 - val_loss: 0.0347\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0300\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0059\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0037 - val_loss: 0.0069\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0082\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0014 - val_loss: 0.0042\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.4789e-04 - val_loss: 0.0023\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.1993e-04 - val_loss: 0.0011\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.9813e-04 - val_loss: 0.0012\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.0081e-04 - val_loss: 7.7914e-04\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4230e-04 - val_loss: 1.8861e-05\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.4792e-05 - val_loss: 6.0149e-05\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.5107e-05 - val_loss: 1.7881e-06\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.5977e-06 - val_loss: 1.0170e-06\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8.2989e-06 - val_loss: 2.5906e-05\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.4207e-06 - val_loss: 4.9993e-06\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5934e-06 - val_loss: 3.5204e-06\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3668e-06 - val_loss: 3.8184e-06\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.9970e-07 - val_loss: 1.5981e-06\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.1788e-07 - val_loss: 1.2293e-07\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9597e-07 - val_loss: 8.1956e-08\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.6164e-08 - val_loss: 1.9372e-07\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.6697e-08 - val_loss: 1.8626e-07\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.3955e-08 - val_loss: 7.4506e-09\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.6146e-09 - val_loss: 5.9605e-08\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7196e-08 - val_loss: 1.1548e-07\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.1470e-08 - val_loss: 0.0000e+00\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.5548e-09 - val_loss: 0.0000e+00\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4662e-09 - val_loss: 0.0000e+00\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9387e-09 - val_loss: 0.0000e+00\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.0274e-09 - val_loss: 0.0000e+00\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.6385e-09 - val_loss: 0.0000e+00\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.4147e-09 - val_loss: 0.0000e+00\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.2681e-09 - val_loss: 0.0000e+00\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.7894e-09 - val_loss: 0.0000e+00\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0465e-09 - val_loss: 0.0000e+00\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.0268e-09 - val_loss: 0.0000e+00\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.9713e-09 - val_loss: 0.0000e+00\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.6183e-09 - val_loss: 0.0000e+00\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.3851e-09 - val_loss: 0.0000e+00\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3507e-09 - val_loss: 0.0000e+00\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.5515e-09 - val_loss: 0.0000e+00\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.2732e-10 - val_loss: 0.0000e+00\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5125e-09 - val_loss: 0.0000e+00\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.1393e-10 - val_loss: 0.0000e+00\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.4996e-09 - val_loss: 3.7253e-09\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.5556e-09 - val_loss: 0.0000e+00\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.4548e-09 - val_loss: 0.0000e+00\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.7692e-09 - val_loss: 0.0000e+00\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.3295e-09 - val_loss: 0.0000e+00\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6268e-09 - val_loss: 0.0000e+00\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4623e-09 - val_loss: 0.0000e+00\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1973e-09 - val_loss: 0.0000e+00\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5111e-09 - val_loss: 0.0000e+00\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3516e-09 - val_loss: 0.0000e+00\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4504e-09 - val_loss: 0.0000e+00\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9030e-09 - val_loss: 0.0000e+00\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9168e-09 - val_loss: 0.0000e+00\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.3939e-09 - val_loss: 0.0000e+00\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2027e-09 - val_loss: 0.0000e+00\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2113e-09 - val_loss: 0.0000e+00\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5425e-09 - val_loss: 0.0000e+00\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.4742e-09 - val_loss: 0.0000e+00\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1890e-09 - val_loss: 0.0000e+00\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.7912e-09 - val_loss: 0.0000e+00\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.5649e-09 - val_loss: 0.0000e+00\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.6316e-09 - val_loss: 0.0000e+00\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2423e-09 - val_loss: 0.0000e+00\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2173e-09 - val_loss: 0.0000e+00\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4333e-09 - val_loss: 0.0000e+00\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.5485e-09 - val_loss: 0.0000e+00\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.8688e-09 - val_loss: 0.0000e+00\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.8747e-09 - val_loss: 0.0000e+00\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.4747e-09 - val_loss: 0.0000e+00\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0543e-09 - val_loss: 0.0000e+00\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1117e-09 - val_loss: 0.0000e+00\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9915e-09 - val_loss: 0.0000e+00\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.8327e-09 - val_loss: 0.0000e+00\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.8487e-09 - val_loss: 0.0000e+00\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.7135e-09 - val_loss: 0.0000e+00\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7562e-09 - val_loss: 0.0000e+00\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4389e-08 - val_loss: 1.3411e-07\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.6040e-08 - val_loss: 4.8429e-08\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0948e-08 - val_loss: 1.1176e-08\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.4236e-09 - val_loss: 1.1176e-08\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.1554e-09 - val_loss: 3.7253e-09\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.0832e-09 - val_loss: 7.4506e-09\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.1697e-09 - val_loss: 3.7253e-09\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.6611e-09 - val_loss: 3.7253e-09\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.4015e-09 - val_loss: 1.1176e-08\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.1101e-09 - val_loss: 7.4506e-09\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.0945e-09 - val_loss: 7.4506e-09\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.0238e-09 - val_loss: 7.4506e-09\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0347e-09 - val_loss: 7.4506e-09\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4685e-09 - val_loss: 7.4506e-09\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9560e-09 - val_loss: 7.4506e-09\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.3973e-10 - val_loss: 7.4506e-09\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8548e-09 - val_loss: 7.4506e-09\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.0045e-09 - val_loss: 7.4506e-09\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7884e-09 - val_loss: 7.4506e-09\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1968e-09 - val_loss: 7.4506e-09\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.9542e-09 - val_loss: 4.8429e-08\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8270e-08 - val_loss: 3.0547e-07\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.7670e-08 - val_loss: 3.7253e-09\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0880e-08 - val_loss: 3.7253e-09\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.0947e-09 - val_loss: 1.1548e-07\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8450e-08 - val_loss: 3.7253e-09\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.3044e-09 - val_loss: 3.7253e-09\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.1118e-09 - val_loss: 0.0000e+00\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.9808e-09 - val_loss: 0.0000e+00\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.1933e-09 - val_loss: 7.4506e-09\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.4308e-08 - val_loss: 1.6019e-07\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.5887e-08 - val_loss: 2.6077e-07\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.3715e-08 - val_loss: 4.9546e-07\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.8209e-08 - val_loss: 1.1176e-08\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3358e-08 - val_loss: 3.7998e-07\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.6518e-08 - val_loss: 6.7055e-08\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.4524e-09 - val_loss: 7.4506e-09\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.1691e-09 - val_loss: 3.7253e-09\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6699e-08 - val_loss: 1.8626e-07\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1517e-08 - val_loss: 5.9605e-08\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.0903e-09 - val_loss: 2.1979e-07\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.9982e-08 - val_loss: 1.7323e-06\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.4136e-07 - val_loss: 4.6939e-07\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2265e-07 - val_loss: 8.0094e-07\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.0997e-08 - val_loss: 7.4506e-09\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.8361e-09 - val_loss: 1.0431e-07\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4809e-08 - val_loss: 5.5879e-08\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.7985e-07 - val_loss: 1.1511e-06\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.2497e-07 - val_loss: 7.4506e-09\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.9730e-07 - val_loss: 7.4022e-06\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.7337e-06 - val_loss: 1.0900e-05\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.5857e-06 - val_loss: 5.1036e-07\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9035e-06 - val_loss: 1.8049e-05\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.7105e-06 - val_loss: 3.8221e-06\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3534e-07 - val_loss: 1.6466e-06\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.9901e-07 - val_loss: 1.5590e-05\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9487e-06 - val_loss: 1.5289e-05\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.9917e-06 - val_loss: 1.7542e-05\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4489e-06 - val_loss: 1.6764e-07\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.4807e-07 - val_loss: 1.6764e-07\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.2399e-07 - val_loss: 5.0291e-07\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4939e-06 - val_loss: 2.7269e-06\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2814e-06 - val_loss: 9.5256e-06\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1815e-06 - val_loss: 9.0525e-07\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.0043e-07 - val_loss: 2.1234e-07\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.0304e-06 - val_loss: 6.8579e-05\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2.4605e-05 - val_loss: 7.3854e-05\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.4515e-05 - val_loss: 7.2632e-05\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.7490e-05 - val_loss: 5.5428e-04\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.0987e-04 - val_loss: 0.0019\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.3702e-04 - val_loss: 6.6999e-05\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2575e-05 - val_loss: 4.9375e-05\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6823e-05 - val_loss: 2.0601e-06\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6773e-05 - val_loss: 2.6050e-04\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.2635e-05 - val_loss: 6.3436e-04\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3363e-05 - val_loss: 1.8254e-07\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.4499e-07 - val_loss: 6.7055e-08\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.3187e-08 - val_loss: 2.4214e-07\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.5346e-08 - val_loss: 9.6858e-08\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.0724e-08 - val_loss: 3.4757e-06\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.5814e-07 - val_loss: 1.4901e-08\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.7634e-08 - val_loss: 0.0000e+00\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.6721e-09 - val_loss: 4.6939e-07\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0378e-07 - val_loss: 2.3842e-07\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.5663e-08 - val_loss: 9.6858e-08\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.5573e-08 - val_loss: 7.4506e-09\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.9857e-10 - val_loss: 7.4506e-09\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.3427e-09 - val_loss: 1.1548e-07\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.4043e-08 - val_loss: 3.3528e-08\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2959e-08 - val_loss: 1.4901e-08\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6707e-07 - val_loss: 6.8173e-07\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.6046e-07 - val_loss: 1.6019e-07\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9338e-07 - val_loss: 8.5682e-08\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.3865e-08 - val_loss: 6.8918e-07\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9953e-07 - val_loss: 5.5879e-08\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9630e-08 - val_loss: 2.3842e-07\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.9368e-08 - val_loss: 5.4389e-07\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9325e-07 - val_loss: 6.8173e-07\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.9154e-07 - val_loss: 1.7323e-06\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.4344e-06 - val_loss: 5.9679e-06\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2233e-06 - val_loss: 2.3842e-07\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.0063e-07 - val_loss: 3.1400e-05\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.9412e-06 - val_loss: 9.8858e-05\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1904e-05 - val_loss: 3.1441e-06\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.5076e-06 - val_loss: 2.7023e-05\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.2371e-06 - val_loss: 2.9020e-05\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.4254e-06 - val_loss: 9.7975e-06\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.4505e-06 - val_loss: 2.9963e-05\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.4643e-06 - val_loss: 2.7332e-05\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.6395e-06 - val_loss: 1.9606e-05\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5764e-05 - val_loss: 1.8572e-04\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.7112e-05 - val_loss: 1.3634e-04\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2636e-05 - val_loss: 1.5646e-07\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.5855e-05 - val_loss: 3.4399e-05\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.8192e-04 - val_loss: 1.0277e-04\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0018 - val_loss: 0.0143\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.2144\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2835 - val_loss: 8.1028\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.7139 - val_loss: 1.7348\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 69.9563 - val_loss: 70.9026\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 315.3077 - val_loss: 45.5263\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 48.0231 - val_loss: 741.6548\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 97.4981 - val_loss: 489.3740\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 221.6369 - val_loss: 1927.7137\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 299.1243 - val_loss: 89.3483\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 46.7723 - val_loss: 297.7478\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 54.5075 - val_loss: 372.0063\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 180.0113 - val_loss: 556.0076\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 206.1741 - val_loss: 116.6667\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 337.3076 - val_loss: 4877.2900\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 771.5447 - val_loss: 1460.3286\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 413.2807 - val_loss: 1273.6542\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2265.2843 - val_loss: 2490.0325\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 104.8813 - val_loss: 681.6716\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 333.0222 - val_loss: 6553.4390\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1868.8098 - val_loss: 4727.9097\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1900.3801 - val_loss: 3251.3477\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2251.1995 - val_loss: 2763.8677\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 341.9405 - val_loss: 5.5015\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51.5661 - val_loss: 21.2849\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 11.9696 - val_loss: 46.8800\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 52.6101 - val_loss: 40.8269\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 209.6098 - val_loss: 693.6431\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 214.1638 - val_loss: 3805.6670\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 572.6555 - val_loss: 2173.3611\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 501.6222 - val_loss: 480.0482\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1106.1384 - val_loss: 20849.5195\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 3819.8379 - val_loss: 29411.7930\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7064.1124 - val_loss: 11443.5928\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3717.4763 - val_loss: 70.4417\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 656.1388 - val_loss: 5428.8599\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1376.1545 - val_loss: 5.4803\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 114.1684 - val_loss: 223.4411\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 44.6144 - val_loss: 44.6821\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 35.6234 - val_loss: 144.4981\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8.9209 - val_loss: 13.7830\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 14.9219 - val_loss: 0.2452\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.7895 - val_loss: 2.7692\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.4904 - val_loss: 232.9431\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31.1901 - val_loss: 8.1716\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 3.0403 - val_loss: 1.8043\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0131\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0475 - val_loss: 0.0153\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0040 - val_loss: 0.0458\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0141 - val_loss: 4.1767e-04\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.0221\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0279\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.7071e-04 - val_loss: 7.6781e-04\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1771e-04 - val_loss: 1.8403e-06\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.9887e-05 - val_loss: 1.2554e-05\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.0359e-06 - val_loss: 3.7830e-05\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.1253e-05 - val_loss: 3.1944e-05\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.2759e-05 - val_loss: 4.5449e-07\n"
     ]
    }
   ],
   "source": [
    "### 학습률 0.1 지정\n",
    "model = Sequential() # 컨테이너 객체 생성\n",
    "# Dense: 전결합층, 1: 뉴런(노드)의 수, input_dim=1: 입력데이터의 가지수\n",
    "# activation='linear': 활성화 함수 입력 -> 출력\n",
    "model.add(Dense(10, input_dim=1, activation='linear'))\n",
    "model.add(Dense(1, activation='linear')) # 입력값은 이전 Layer의 노드수 10개\n",
    "# optimizer='adam': 오차역전파 알고리즘, loss='mse': 평균제곱오차\n",
    "model.compile(optimizer=Adam(lr=0.1), loss='mse')\n",
    "model.summary() # 네트워크 확인, Param: 가중치, 편향, 100만개이상이면 GPU 권장\n",
    "# Dense: 전결합층 기반의 네트워크\n",
    "# Output Shape: (None, 1) 출력은 2차원의 형태임, 컬럼이 1개임\n",
    "# None: 입력값에 따라 출력값의 갯수가 결정된으로 출력값은 가변적임.\n",
    "hist = model.fit(x_train, y_train, validation_split=0.2, shuffle=True,\n",
    "                epochs=300, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x360 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "# plt.figure(figsize=(6,4)) # ERROR\n",
    "fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "# 왼쪽 y 축 설정\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 2252675.7500]) # 값을 반영하여 변경 ★\n",
    "\n",
    "# 축 레이블 설정\n",
    "loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "loss_ax.set_ylabel('loss')   # 오차\n",
    "\n",
    "loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "\n",
    "plt.show()\n",
    "# train loss: 하강하면 훈련이 정상적으로 진행되고 있음\n",
    "# val loss: 하강하면 훈련되지 않은 데이터를 대상으로 한 테스트도 정상적으로 진행됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1030720.0147 - val_loss: 3281141.0000\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 844426.2353 - val_loss: 3192615.5000\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 827471.8971 - val_loss: 3075524.0000\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 881329.8456 - val_loss: 2926980.0000\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 599493.1324 - val_loss: 2769450.2500\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 657928.1379 - val_loss: 2572979.5000\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 724160.6360 - val_loss: 2352101.7500\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 518979.1673 - val_loss: 2127377.2500\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 535957.8989 - val_loss: 1867631.1250\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 452363.9164 - val_loss: 1612325.5000\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 551147.0221 - val_loss: 1330106.1250\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 316098.5653 - val_loss: 1089369.5000\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 225560.5777 - val_loss: 865662.4375\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 189061.6719 - val_loss: 658151.3750\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 119260.3129 - val_loss: 471127.7500\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 139200.2799 - val_loss: 323722.9062\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 60688.3208 - val_loss: 224849.4688\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 45825.0170 - val_loss: 144744.0781\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 28935.5005 - val_loss: 89048.7188\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 10948.8221 - val_loss: 58588.5664\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 11690.2011 - val_loss: 34765.0898\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2708.2241 - val_loss: 23753.3086\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5601.8724 - val_loss: 14851.7559\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3632.1834 - val_loss: 10751.4424\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1672.7776 - val_loss: 8035.3818\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1347.1392 - val_loss: 6728.2832\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2132.6406 - val_loss: 5818.4023\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1961.1727 - val_loss: 5162.9155\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1833.3633 - val_loss: 5217.7441\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2348.2164 - val_loss: 4499.2344\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2678.8478 - val_loss: 4216.8389\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2455.9148 - val_loss: 4371.7515\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1605.2751 - val_loss: 4117.3809\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1633.2843 - val_loss: 4403.9302\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1309.9800 - val_loss: 4015.6912\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2753.8334 - val_loss: 3998.0920\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2653.5385 - val_loss: 4038.5193\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1636.9201 - val_loss: 3889.5398\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1119.0350 - val_loss: 4110.8213\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2141.7412 - val_loss: 4166.2534\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 2593.3036 - val_loss: 3682.3430\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1337.2335 - val_loss: 3799.3594\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1269.0837 - val_loss: 3502.9094\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1990.8050 - val_loss: 3796.1802\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 831.5744 - val_loss: 3723.7141\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1884.3110 - val_loss: 3794.4121\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 965.3604 - val_loss: 3312.8779\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1764.1544 - val_loss: 3392.1108\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1276.7470 - val_loss: 3242.6990\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1501.0991 - val_loss: 3262.2378\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1617.6989 - val_loss: 3421.4780\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1477.1114 - val_loss: 3588.6982\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 913.4462 - val_loss: 2958.9871\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1138.8310 - val_loss: 2841.3491\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1434.7011 - val_loss: 3123.9990\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1518.5684 - val_loss: 3177.2676\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1839.1832 - val_loss: 3129.7566\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1332.3491 - val_loss: 2879.4570\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1911.6213 - val_loss: 3010.7891\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1190.4161 - val_loss: 2648.7415\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1554.6852 - val_loss: 2693.6982\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 734.6715 - val_loss: 3117.6973\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1086.6758 - val_loss: 2648.3240\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1212.6624 - val_loss: 2742.5176\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1390.9988 - val_loss: 2719.8838\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1108.4550 - val_loss: 2941.6116\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1099.6793 - val_loss: 2595.5957\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 921.7090 - val_loss: 2566.5713\n",
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1024.4714 - val_loss: 2327.0571\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1004.3577 - val_loss: 2597.6533\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1154.7191 - val_loss: 2320.7134\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1335.0510 - val_loss: 2126.6416\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1075.4536 - val_loss: 2269.3076\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1133.0330 - val_loss: 2081.2017\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1187.6359 - val_loss: 2215.4546\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 974.0171 - val_loss: 2388.3623\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1202.8301 - val_loss: 2351.5781\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 788.0607 - val_loss: 1942.3943\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1031.6044 - val_loss: 1754.7915\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 728.4633 - val_loss: 2233.7810\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1170.0749 - val_loss: 1974.7314\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1039.2869 - val_loss: 1828.6296\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 438.1862 - val_loss: 1611.0620\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 924.9854 - val_loss: 2006.0325\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 712.2213 - val_loss: 1693.8796\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 891.9018 - val_loss: 1807.5961\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 560.6914 - val_loss: 1812.9587\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 631.6535 - val_loss: 1576.4634\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 658.9442 - val_loss: 1546.4337\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 632.9920 - val_loss: 1626.7157\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 691.0179 - val_loss: 1589.3225\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 572.4693 - val_loss: 1615.6404\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 509.8259 - val_loss: 1584.2969\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 344.9729 - val_loss: 1325.8092\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 749.0629 - val_loss: 1768.3433\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 699.7206 - val_loss: 1431.7710\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 830.6094 - val_loss: 1105.9786\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 462.4137 - val_loss: 1329.5281\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 710.0719 - val_loss: 1247.7085\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 483.3696 - val_loss: 1415.4789\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 627.6582 - val_loss: 1438.6913\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 592.9392 - val_loss: 1003.2964\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 288.7242 - val_loss: 1145.6925\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 445.0412 - val_loss: 1098.6205\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 362.2658 - val_loss: 1050.9109\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 519.0960 - val_loss: 1279.9147\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 562.0188 - val_loss: 964.5507\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 421.4871 - val_loss: 1035.1141\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 477.0775 - val_loss: 942.8832\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 597.4269 - val_loss: 886.3152\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 346.2751 - val_loss: 1068.4265\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 535.9227 - val_loss: 1051.5581\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 388.5528 - val_loss: 845.7429\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 257.6040 - val_loss: 864.4844\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 274.5148 - val_loss: 753.0707\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 515.3902 - val_loss: 908.4009\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 246.9557 - val_loss: 691.0725\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 440.5062 - val_loss: 714.3347\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 259.6752 - val_loss: 710.4770\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 292.0971 - val_loss: 774.7838\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 240.2291 - val_loss: 764.0540\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 407.3570 - val_loss: 730.9573\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 241.2437 - val_loss: 706.6866\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 208.1767 - val_loss: 495.8191\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 345.2144 - val_loss: 604.3058\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 281.2911 - val_loss: 688.8002\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 282.7547 - val_loss: 518.3212\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 347.3598 - val_loss: 548.1416\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 226.0821 - val_loss: 560.9731\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 168.3545 - val_loss: 380.8079\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 182.2574 - val_loss: 512.2946\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 235.6861 - val_loss: 472.5621\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 197.8019 - val_loss: 382.5649\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 264.7121 - val_loss: 449.1808\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 249.2913 - val_loss: 489.0904\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 314.0637 - val_loss: 466.6479\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 176.6048 - val_loss: 378.9821\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 144.5233 - val_loss: 327.1754\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 194.3017 - val_loss: 420.5134\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 147.2226 - val_loss: 310.6718\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 128.7615 - val_loss: 322.9827\n",
      "Epoch 142/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 198.9517 - val_loss: 385.8220\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 220.4731 - val_loss: 295.2364\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 115.8370 - val_loss: 288.6534\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 164.4789 - val_loss: 332.0728\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 176.9594 - val_loss: 278.5121\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 107.1752 - val_loss: 299.6514\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 131.5801 - val_loss: 233.8763\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 93.3612 - val_loss: 258.0849\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 179.2856 - val_loss: 250.6986\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 131.2543 - val_loss: 192.0944\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 118.0226 - val_loss: 230.7731\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 67.1202 - val_loss: 226.8798\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 84.5813 - val_loss: 209.4423\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 69.8932 - val_loss: 204.7915\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 86.4060 - val_loss: 190.4487\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 95.9075 - val_loss: 177.1610\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 60.1484 - val_loss: 166.9133\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 69.3325 - val_loss: 181.5015\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 58.3804 - val_loss: 155.6638\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 66.2149 - val_loss: 142.1608\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 72.3945 - val_loss: 161.3972\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.7034 - val_loss: 169.9165\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 34.1972 - val_loss: 114.8382\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 73.9836 - val_loss: 150.0920\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.8938 - val_loss: 129.8308\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 55.8235 - val_loss: 77.3193\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 40.4013 - val_loss: 117.3418\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 46.5251 - val_loss: 113.3665\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 42.1211 - val_loss: 130.1214\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 50.2853 - val_loss: 91.4376\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 48.0982 - val_loss: 79.8087\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 24.0568 - val_loss: 78.2177\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.1706 - val_loss: 87.5173\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 36.2729 - val_loss: 61.8434\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 26.3204 - val_loss: 81.2695\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 32.9079 - val_loss: 71.4122\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 24.0942 - val_loss: 57.2447\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 50.2994 - val_loss: 63.7103\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 27.5147 - val_loss: 72.2311\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 20.0812 - val_loss: 37.9122\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.7289 - val_loss: 59.1648\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27.4331 - val_loss: 54.4791\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30.5232 - val_loss: 40.8234\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16.7914 - val_loss: 43.2593\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13.1951 - val_loss: 37.2649\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 26.0156 - val_loss: 57.8865\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 19.5604 - val_loss: 19.6867\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 19.8405 - val_loss: 36.2209\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 13.5850 - val_loss: 35.5401\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 15.3388 - val_loss: 35.6531\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12.8696 - val_loss: 29.5587\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12.8776 - val_loss: 26.7565\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13.2995 - val_loss: 33.1421\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 16.3269 - val_loss: 24.2463\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.8965 - val_loss: 15.9370\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 13.3960 - val_loss: 20.3105\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8.4213 - val_loss: 28.2222\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 10.7277 - val_loss: 14.5520\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 11.8113 - val_loss: 21.4162\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12.1776 - val_loss: 17.6305\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 10.5953 - val_loss: 11.9710\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8.5394 - val_loss: 14.5755\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.9925 - val_loss: 18.0693\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.0195 - val_loss: 9.2755\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 5.1344 - val_loss: 12.4794\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 3.6741 - val_loss: 11.2623\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.6905 - val_loss: 9.7857\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.0557 - val_loss: 7.8868\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.6288 - val_loss: 13.2529\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.9279 - val_loss: 7.9286\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.4997 - val_loss: 6.6180\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.3201 - val_loss: 8.4776\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.8037 - val_loss: 4.5131\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.1182 - val_loss: 7.2294\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.7232 - val_loss: 5.6981\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7808 - val_loss: 2.9601\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 3.1063 - val_loss: 7.7317\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.0378 - val_loss: 3.0781\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.7657 - val_loss: 4.0356\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4891 - val_loss: 3.9951\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4846 - val_loss: 4.1152\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.6844 - val_loss: 3.5969\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7204 - val_loss: 3.2441\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.2083 - val_loss: 2.4583\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.9305 - val_loss: 2.9749\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.7525 - val_loss: 1.6049\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.1828 - val_loss: 2.8590\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.1448 - val_loss: 1.4237\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.8093 - val_loss: 2.2501\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.7598 - val_loss: 1.2229\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.1398 - val_loss: 1.6319\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.0241 - val_loss: 2.1824\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5743 - val_loss: 0.7409\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6975 - val_loss: 1.6418\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.5501 - val_loss: 1.0217\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4566 - val_loss: 0.8848\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3896 - val_loss: 0.8449\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4146 - val_loss: 0.8431\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2730 - val_loss: 0.8545\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3920 - val_loss: 0.9302\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.4759 - val_loss: 0.4934\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2407 - val_loss: 0.5501\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.3577 - val_loss: 0.5061\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.2288 - val_loss: 0.5759\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1745 - val_loss: 0.3967\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.2186 - val_loss: 0.3860\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1718 - val_loss: 0.3489\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1462 - val_loss: 0.3329\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1789 - val_loss: 0.2636\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1665 - val_loss: 0.2586\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.1005 - val_loss: 0.2534\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1345 - val_loss: 0.2341\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0992 - val_loss: 0.1503\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0730 - val_loss: 0.1674\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0913 - val_loss: 0.1899\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0854 - val_loss: 0.0894\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.1013 - val_loss: 0.1437\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0746 - val_loss: 0.0563\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0509 - val_loss: 0.1101\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.0820\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0315 - val_loss: 0.0727\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0276 - val_loss: 0.0935\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0496\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0398 - val_loss: 0.0630\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0304 - val_loss: 0.0333\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0243 - val_loss: 0.0660\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0348\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0315 - val_loss: 0.0420\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0307\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0291\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0236\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0394\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0341\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0087 - val_loss: 0.0104\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0146\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0152\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0050 - val_loss: 0.0111\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0080\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0035 - val_loss: 0.0067\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0069\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0030 - val_loss: 0.0078\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0023 - val_loss: 0.0063\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.2242e-04 - val_loss: 0.0012\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4.7235e-04 - val_loss: 0.0025\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8.6697e-04 - val_loss: 0.0010\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 8.3758e-04 - val_loss: 0.0012\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 3.2443e-04 - val_loss: 0.0020\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.5268e-04 - val_loss: 4.8918e-04\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 3.1270e-04 - val_loss: 6.1322e-04\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.2348e-04 - val_loss: 8.2442e-04\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1.8472e-04 - val_loss: 2.5109e-04\n"
     ]
    }
   ],
   "source": [
    "### 학습률 0.01 지정\n",
    "model = Sequential() # 컨테이너 객체 생성\n",
    "# Dense: 전결합층, 1: 뉴런(노드)의 수, input_dim=1: 입력데이터의 가지수\n",
    "# activation='linear': 활성화 함수 입력 -> 출력\n",
    "model.add(Dense(10, input_dim=1, activation='linear'))\n",
    "model.add(Dense(1, activation='linear')) # 입력값은 이전 Layer의 노드수 10개\n",
    "# optimizer='adam': 오차역전파 알고리즘, loss='mse': 평균제곱오차\n",
    "model.compile(optimizer=Adam(lr=0.01), loss='mse')\n",
    "model.summary() # 네트워크 확인, Param: 가중치, 편향, 100만개이상이면 GPU 권장\n",
    "# Dense: 전결합층 기반의 네트워크\n",
    "# Output Shape: (None, 1) 출력은 2차원의 형태임, 컬럼이 1개임\n",
    "# None: 입력값에 따라 출력값의 갯수가 결정된으로 출력값은 가변적임.\n",
    "hist = model.fit(x_train, y_train, validation_split=0.2, shuffle=True,\n",
    "                epochs=300, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAE+CAYAAAAnGdyNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAABFoElEQVR4nO3deXxcdb3/8dd3JstkbfY0TZqk+4a0hQIta5W9ssjiFUG9CgoXL7JfcBetaIULFkW4LAr+VOAiLiwK4q0USrHQFqHQQvctXdMsTdI063x/f3wzzCRN0qRJ5kyS9/PxyOPMnDk588k8xvrm8z3n+zXWWkRERETEez6vCxARERERR8FMREREJEYomImIiIjECAUzERERkRihYCYiIiISIxTMRERERGLEgAQzY0yuMeZOY8z8tueTjDGLjDFLjTF3Rxw33xjzatv+ad0dKyIiIjLUDVTH7B6gEYhve74QuMpaexJQaow5wRhzCpBvrT0NuAa4u6tjB6hGERERkZgyIMHMWvsF4DUAY0wcELDWbml7+Q/AHOAs4Mm2498Hsro5VkRERGTIi4vCe+QCFRHPK4ApQB5QHrG/Bcjv4thDGGOuBq4GSElJOXby5Mn9WLJI1xobt9PcvI/U1JlelzLw9u6F7dth+nSIi4N166C21j2ePt0d09wMq1ZBdjaUlnparojIYLBy5cp91trczl6LRjCrBjIinmfiAllS2+OQIFDZxbGHsNY+DDwMMGvWLLtixYr+qlekW2Vl97Fhw42ceOJLJCTkeF3OwHrkEbj6anjhBSgqglNOgddfh5QUCP1vbvNmGDsWzjwTnnzS23pFRAYBY8zWrl4b8LsyrbUHgURjTGHbrouBRcAS4NK2AqcCZd0cKxIzAoGxADQ0bPK4kigIBNy2sdFtGxrctqkpfExo38GD0atLRGSIikbHDOBm4BljTCPwnLX2A2PMWmCeMWYJUIu7AaDTY6NUo0iPJCW5YHbw4CbS04/3uJoBlpjotqHw1V0wC21FROSIDVgws9YuBha3PV5Oh4v4rbVB4NpOfu+QY0ViSSBQCkBNzTL8/hSyss7G50vwtqiBEgpmHTtmra3ux+9Xx0xEpB9Fq2MWdc3NzZSVldGg/4rvsUAgQFFREfHx8Yc/eBjz+1OIj89nx4772LHjPiZOfIRRo77sdVkDo6uhTHAX/SuYiYj0qyEbzMrKykhLS6O0tBRjjNflxDxrLRUVFZSVlTFmzBivy4l5Eyc+QEPDVrZvv4vq6kVDN5h1NZQJLqwFAuFApv8IEhHpsyEbzBoaGhTKesEYQ3Z2NuXlnd4EKx3k5l4MQG3tCqqqFmGtHZrftc6GMhMT3fPQdWbqmImI9JshvVbmkPw/ygGkz6v3MjM/QXPzHurrh+g9Kp0NZaanu8cKZiIi/W5IBzORgZaR8XEAqqtf8biSARI5lNnS4n66CmYayhQR6TMFswG0ePHiXh3/7W9/u1c3K8yePbuXFUl/CwTGkJhYTFXVP7wuZWBEDmWGumbqmImIDBgFswH09a9/vVfH//CHPyQQGjqSQcEYQ2bmJ6iuXoybAWaIiRzKDAWw7oKZtdGtT0RkiBmyF/9HWr/+Rurq3unXc6amzmDChIVdvv61r32NNWvWMHfuXB544AHuuusuSktLefHFF3njjTe4+eabWbVqFTU1NTz44IMcf/zxzJ07l5deeolly5bx6KOPUl9fz/r16/nyl7/MDTfc0OV71dbWcu2117Jjxw7q6+u57rrr+PznP89zzz3HggUL8Pl83HLLLZxyyil84QtfoLa2lkmTJvHoo4/262cyXI0YcSq7dz9Off2HpKRM9bqc/hU5lHm4YGatm0IjYYjO6SYiEgXDIph54ec//znLly9vN5w5atQo3nzzTcANW+bm5vLqq6/yyCOPcPzx7WeQ37p1K4sXL6alpYUZM2Z0G8wWLFjAWWedxRe+8AUaGxuZO3cu5557Lo899hi/+c1vGDduHMFgkOeff55jjz2W+fPnEwwOwe6OR9LT3XzINTXLhm4wi+yYjRgR3gfthzAPHlQwExHpg2ERzLrrbEXTiSeeCMDBgwf50Y9+RGJiIgcOHKC2trbTY/1+P36/n/RQh6IL77zzDrfccgsAiYmJHH/88WzevJmFCxdy//33k5SUxM0338x5553H5s2bueGGG/jsZz+ra9T6SXLyROLiMqipWUZBwZVel9O/ejOUCS6YhYKbiIj0mq4xG0AtLS3tnsfFuRz817/+lby8PBYsWMDcuXM7/d3IqSsON43FtGnTeOmllwBoamri3XffZcKECeTl5XH33Xdz0kknMX/+fJqamrjxxhu59957ueaaa7o9p/ScMT7S02dTU7PM61L6X1wcGNOzocyOj0VEpNcUzAbQqaeeyvHHH8/atWvb7Z89ezbPPPMMZ599Nu+++26f3+eb3/wmf/rTnzjttNM466yzuPXWW8nIyODmm2/m1FNPZcGCBVxyySUsXryYE044gTPPPJNPfepTfX5fCUtPn82BA+/T0lLjdSn9y5jwhLI97ZiJiMgRGxZDmV659957P3r8+OOPf/S4sLCQlStXHnJ86Hq0uXPntuukLVvWeScmtD8jI4Pf//73h7z+4IMPHrLv3HPP7Unp0kvp6bMBS23tcjIzT/e6nP4VCCiYiYhEiTpmIv0gLe0EgKE5nJmYqKFMEZEoUTAT6Qfx8RkkJ09h//7XvS6l/x2uY9bxrkwRETliCmYi/SQr6xyqqv5BS8t+r0vpXx07Zh2ny2hogPh491jBTESkTxTMRPpJbu6nsbaJffue97qU/tWTi/8zM8OPRUTkiCmYifST9PQTSEwsorz80BsxBrWeXPwfCmbqmImI9ImCmUg/McZHTs4lVFb+bWhNm9GTi/8VzERE+oWCmccWL17c6WLnXe2X2JaX92msbWTfvme9LqX/aChTRCRqFMxE+lF6+hySksazc+ehc8gNWpFDmT6fC2o+nzpmIiIDYHhMMHvjjfDOO/17zhkzYOHCLl8+55xzePTRRykqKuKdd97hZz/7GV/96lf5xje+wcGDB5k4cSK/+tWvevRWb7zxBt/61rew1hIfH89DDz3E2LFjufbaa1m1ahXBYJDXXnuNF198kQULFuDz+bjlllu46KKL+udvlR4zxkdh4XVs2HAjNTUrSE+f5XVJfRc5lBkIhFcDiJwuIyMj/FhERI7Y8AhmHvjSl77EE088wW233cZjjz3Gtddey5gxY/jb3/6GMYYzzjiDHTt29Ohc119/PS+++CK5ubksX76c2267jUceeYQ1a9awdOlSrLUYY3jsscf4zW9+w7hx4wgGgwP8F0pXRo78Ips3f5sdO35OevqvvS6n7yKHMkOLmicktJ8uIzk5HOBEROSIDY9g1k1na6B86lOf4uyzz+amm25i3bp1HHfccfz1r3/lxRdfJDU1lcrKSmpraw97nvLyckaNGkVubi4Axx13HDt27CAzM5NbbrmF6667jjlz5nDFFVewcOFC7r//fpKSkrj55pvJCHUxJKri4kYwcuQX2bnzYbKz55GX9xmvS+qbyKHMyGDW1ATWhvcHAl13zPbsgVWr4Mwzo1e3iMggpGvMBkhiYiLTp0/nxz/+MZ/+9KcB+P73v89Pf/pT5s+fjzGmR+fJyclh+/btVFRUALBy5UrGjRtHc3Mz8+bN4/777+eFF17gvffeIy8vj7vvvpuTTjqJ+fPnD9jfJodXXPxNUlOns2bNZaxZ8zlaWwdxJ6njUCaEg1lLCwSDbn9SUtfB7L774JOfdEFORES6NDw6Zh656qqrOPfcc9mwYQMAF110EccccwxHH300hYWFPTqHMYaFCxdy4YUXkpCQQEZGBg888AAVFRVceOGFpKSkkJOTw4QJE7jppptYvXo1fr+fO++8cyD/NDmMxMQCZs58g23bfsSWLd+jsbGMo476M/HxGV6X1ntdDWU2NYWHLkPBrKuhzO3bobnZBbnQKgEiInIIBbMBdPTRR7e7juzrX//6IVNgTJ48mblz5x7yu3Pnzv1o/2mnncbrrx+6BuObb77Z7vmDDw6hOwGHAJ8vjtLS75KUNJ4PPvg8ZWULGTPmDq/L6r3uhjIjg1l3Q5k7d7ptY6OCmYhINzSUKTLA8vMvJxAo4eDBdV6XcmRCHbO6unAwC92VGQpihxvKDAWz0J2cIiLSKQUzkSgIBEpoaNjmdRlHpu3GExYvPvKhTAUzEZEeGdJDmaFpJKRnrC7MHjCJiSVUVy/yuowjc+21UFAATz4Jp5/u9oWmywgFsaQk91Nff+jv19VBTdsSVaEpNkREpFNDNpgFAgEqKirIzs5WOOsBay0VFRUEQh0R6VeBQDGNjTsJBpvx+QbZNVZ+P1xyifsJ6eoas7a7h9vZtSv8WB0zEZFuDdlgVlRURFlZGeXl5V6XMmgEAgGKioq8LmNICgRKgCCNjTtISir1upy+S0hwXbCeDGWGhjFBwUxE5DCGbDCLj49nzJgxXpchAkBiYjEAjY1bh04w6+was84u/o8MZhrKFBHpli7+F4kC1zFj8N4A0FFvpstQx0xEpMcUzESiIDFxNAANDVs9rqSf9Ga6DAUzEZEeUzATiQK/P4n4+DwaG4dQxyzyrsyeXmOmoUwRkW4pmIlESSBQPHQ6Zl0NZTY1QWtr+2N37gzPf6aOmYhItxTMRKIkMbFkaHXMIoNZaB4zOLRrtnMnlJa6xwpmIiLdUjATiRI3+//WoTGRb1d3ZUL7YGatC2ahO6QVzEREuqVgJhIlgUAxweBBmps7mYR1sOkYzBITw8Es8gaAmhq3GkCoY6ZrzEREuqVgJhIlgUApAPX1a7wtpD9E3pWZkAA+X/g6sshgFrrwX0OZIiI9omAmEiUZGR/H709j586HvS6l7xIS3DBlXV04kHU2lBlajqnEzeOmYCYi0j0FM5EoiYtLZ+TIKykv/18aG3d4XU7fJCS47f794WCWnOy2Bw6Ej9uzx21Hu3ncNJQpItI9BTORKCoquh5rW9mx4wGvS+mbUDCrqQkHs/R0t62tDR8XCmbFbkkqdcxERLqnYCYSRUlJY8nJuZCdOx+gqanc63KOXCiY7dhxaDCrqQkft3s3xMdDfr57rmAmItItBTORKBsz5k5aW+vYtOnrXpdy5LKy3HblSsjMdI87C2Z79kBengtnPp+GMkVEDiPO6wJEhpuUlKkUFd3E9u13U1BwFSNGnOh1Sb136aWwZAlUVcGUKW5fV8Es1C0LTbEhIiJdimrHzBhzszHmVWPMUmPMTGPMJGPMorbnd0ccNz/iuGnRrFEkGkpKvkt8fD7btv3E61KOjN8PJ58M558P48e7fWlpbttVMAtNsSEiIl2KWsfMGJMBXADMBcYBP217/6ustVuMMb83xpwAJAD51trTjDFHAXcD86JVp0g0xMWlkpf3b+za9QitrQfw+1O8Lqnv4uLcnZkdrzGbPt09Di18LiIiXYpmx6y17f0SgBygHAhYa7e0vf4HYA5wFvAkgLX2fSCrs5MZY642xqwwxqwoLx/EF1HLsJWTcxHBYAOVlX/zupT+k57uptAACAZh714NZYqI9ELUgpm1thZ4DfgAeA54DIhcm6YCyATycKEtpMUYc0id1tqHrbWzrLWzcnNzB65wkQEyYsQpxMVlsW/fn70upf+kp4c7ZlVV0NKiYCYi0gvRHMr8JBCPG8bMxHXIghGHZOICWVLb45CgtTbyOJEhweeLIzv7fCoqniUYbMbni/e6pL4bMSIczEJzmEVeY6ahTBGRbkVzKLME2GOttUANkAZkGWMK216/GFgELAEuBTDGTAXKolijSFTl5HyKlpZqKiqe97qU/hHZMQsFs5Ej3VYdMxGRw4rmdBmPA78yxrwKJAIPAe8AzxhjGoHnrLUfGGPWAvOMMUuAWuCaKNYoElXZ2fNITp7K+vXXk5l5OnFxI7wuqW/S0911ZeAu/AcNZYqI9ELUgpm1th64rJOX5nQ4LghcG5WiRDzm8yUwefJjvP32HDZuvJVJkx7xuqS+6axjpukyRER6TDP/i3gsPf14ioquZ9euX9LUtNfrcvqmYzCLiwuvDKDpMkREDkvBTCQG5OVdAViqqv7udSl9Ewpm1oYnl/W1/TOjoUwRkcNSMBOJAWlpxxAXlz345zRLT4fWVjh40F1jFhrGBA1lioj0gIKZSAwwxkdW1plUVr7MoJ4dJnK9zMjlmEBDmSIiPaBgJhIjMjPPprl5D3V1q7wu5ciFgtn+/Yd2zLoaynz9dXjllejUJyIS46I5XYaIdCMr6ywAqqr+RlraDG+LOVKhYLZvH+zaBcXF4de6Gsr86lfdGpvLlkWnRhGRGKaOmUiMSEwcRUrK0VRUvOh1KUcuFMxWr3Y3AIwZE36ts6HMffvgvfegvj56NYqIxDAFM5EYkp19Hvv3v05zc6XXpRyZUDB79123LS0Nv9bZUOaSJW7b0DDgpYmIDAYKZiIxJCfnAqCVyspB2jULBbNVbdfJdeyYdQxmr77qtgpmIiKAgplITElLO474+Hz27XvO61KOTGQw8/uhsDD8WmeLmC9e7LYKZiIigIKZSEwxxkdOzvlUVr5EMDgI5/yKnC5j9Gg3839IQoKb46y11T2vqgoHuIMHo1+riEgMUjATiTHZ2RfQ2lpDdfVir0vpvYQECATc48hhzNBrAM3NbrtkibtBYM4cdcxERNoomInEmMzMM4iPz2Xbtru8LuXIhLpmkRf+gxvKhPB1Zps2ue2sWdDS4n5ERIY5BTORGOP3J1FS8i2qqxdRVbXI63J6r6tgFuqYha4zC02RkZPjtuqaiYgomInEooKCa0hMHM2mTd/EWut1Ob0TCmZdDWWGOmb19e76srQ091zBTEREwUwkFvn9AUpKvk1t7Vvs3/+61+X0Tk+HMuvr3Yz/SUnuuYKZiIiCmUisys+/Ar8/jV27HvW6lN45XMcscihTwUxEpB0FM5EY5fenkJd3OeXlv6e5udrrcnouPR3i46GgoP3+zoYyk5PDd3FqygwREQUzkVg2atRXCAYPsnfvk16X0nPnnANf+pK7fixSV0OZoWCmjpmIiIKZSCxLTT2G1NQZ7N79uNel9NwVV8BDDx26v+NQ5oEDGsoUEelAwUwkhhljyM29lNrat2hq2uN1OX2joUwRkcNSMBOJcVlZ8wCoqBikC5uHHC6YqWMmIqJgJhLrUlNnkJAwisrKv3hdSt+ErjHreFemgpmIyEcUzERinDGG7Ox5VFa+TDDY7HU5R66rjpmuMRMR+YiCmcggkJU1j9bWmsE32WwkXWMmInJYCmYig0Bm5hn4fCls3HjL4JrTLJKGMkVEDkvBTGQQiItLY9q033PgwPu89965BIONXpfUe5EdM2tdMEtJUTATEYmgYCYySGRnn8ukSb+kpmYZlZUveV1O70UGs6YmCAY1lCki0oGCmcggkpd3GX5/OhUVL3hdSu9FzvxfX+8eJyeDz+dCmzpmIiIKZiKDic8XT1bWOVRU/AVrg16X0zuRM/9HBjNwXTMFMxERBTORwSY7+zyamnZRV/cvr0vpnfh4t+3YMQMFMxGRNgpmIoNMVta5gGHfvue9LqV3fD4XzjoLZklJusZMRAQFM5FBJyEhh/T0OVRUDLJgBm44U0OZIiJdUjATGYRycy+mru5t6uvXe11K7yQkaChTRKQbCmYig1Bu7mcAw969T3hdSu8omImIdEvBTGQQCgSKyMg4jT17nsBa63U5PZeY2PlQpq4xExEBFMxEBq28vCs4eHAddXVve11Kz6ljJiLSLQUzkUEqN/cSjEmgrOw+r0vpOQUzEZFuKZiJDFLx8ZmMHn0re/b8hr17f+91OT2Tng7V1RrKFBHpgoKZyCBWWnoHaWnHs27d1TQ27vK6nMMrKIBdu8LBLCnJbdUxExEBFMxEBjWfL57Jkx+npaV6cNyhGRnMAgE36SwomImItFEwExnkUlKmkJIynfLyP3ldyuEVFEBVFVRWhocxQcFMRKSNgpnIEJCbexE1NW/Q1LTH61K6V1Dgths3tg9musZMRARQMBMZEnJyLgYs+/Y963Up3Rs1ym03bDi0Y9baCi0t3tQlIhIjFMxEhoCUlKMIBMaxb1+MD2eGOmZlZYcGM9BwpogMewpmIkOAMYbc3IupqlpEc3OF1+V0LRTMrIWUlPD+UDDTcKaIDHNRDWbGmOONMa8ZY5YaY24zxkwyxixqe353xHHzjTGvtu2fFs0aRQarvLzLsbY5tuc0y80Fv9897niNGahjJiLDXtSCmTEmHvgucKG19iRr7V3AQuAqa+1JQKkx5gRjzClAvrX2NOAa4O4uTyoiH0lNnU5y8jT27Pmt16V0zeeD/Hz3WEOZIiKHiGbH7FxgK/BkW5fseCBgrd3S9vofgDnAWcCTANba94GsKNYoMmgZY8jP/xw1NUs5eHCT1+V0LXQDgIKZiMghohnMJuBC1nnAVcD/ApEXw1QAmUAeUB6xv8UYc0idxpirjTErjDErysvLO74sMizl518OwJ49v/O4km6ErjPrLJjpGjMRGeaiGcxagJettS1tXbJKXBALycQFsv0d9gettcGOJ7PWPmytnWWtnZWbmzuAZYsMHoFAMRkZp7Nz50MEg01el9O5zoKZrjETEQGiG8z+iRvOxBiTD9QCCcaYwrbXLwYWAUuAS9uOmwqURbFGkUFv9OhbaGrawd69T3ldSue665gpmInIMBcXrTey1r5ljFlrjFmK657djAuGzxhjGoHnrLUfGGPWAvOMMUtw4e2aaNUoMhRkZZ1DSspRbN/+3+Tnfx5jjNcltadgJiLSpagFMwBr7XeA73TYPafDMUHg2qgVJTLEGGMYPfpWPvzwi1RW/pXs7E96XVJ7nV38HxrKPHAAVq6EY4+Nfl0iIjFAE8yKDEF5eZ8lEBjLpk3fopNLNL3VXcdswQKYNQs+/DD6dYmIxAAFM5EhyOdLYMyY+Rw48G7sXWs2fjzk5cGUKeF9oWC2apXbrlsX/bpERGKAgpnIEJWXdxmpqTPYvPnbBIPNXpcTlpEBe/bAxz8e3hcKZiFbt0a1JBGRWKFgJjJEGeOjtPQHNDRsprz8Ga/L6V5yslsV4OKLITGx82DW0gL790e/NhGRKFIwExnCsrM/SVLSRMrKfoq11utyuhYIwPPPw0MPQXFx58HsJz9xw6BVVdGvT0QkShTMRIYwY3wUFd1Abe1yamre8Lqc7s2bBzk5UFLSeTBbswb27YOf/jT6tYmIRImCmcgQN3LkvxMXl0lZ2UKvS+mZkhLYtu3Q/Tt3uu3ChVBZGdWSRESiRcFMZIjz+1MoKPgy5eV/orFxp9flHF5Jibs5oONkszt3wsc+BrW1LpyJiAxBCmYiw0BBwdVAK7t2/dLrUg6vpMRtI7tm1sKOHXD66XDOOfC737l9IiJDjIKZyDCQnDyezMyz2LXrYYLBFq/L6V4omEVeZ1Zb61YFGDUKLrkENm0Kz3kmIjKEKJiJDBOjRv0HjY1lVFS84HUp3essmIWuLysshAsucFNr/OlP0a9NRGSAKZiJDBPZ2ecTCIxh69b5sT11RmGhC15bt7rrzELDmOA6Znl5cPLJ8Mc/eluniMgAUDATGSZ8vjhKS++gru5t9u2L4VATH+/C2SuvuDnNfvCDcMcstAD6RRfBe+/Bhg3e1SkiMgAUzESGkfz8K0hOnszmzd/B2lavy+laSQksXQrl5S6ghYJZaAH0s85y22XLvKlPRGSAKJiJDCPG+Ckt/QH19R+wZ88TXpfTtSlTYMQIdxfm229DWRmkpbkfgKwst62r865GEZEBoGAmMszk5l5CauoMtmy5I7YWN4/005/C2rVw+eXujszXXnPDmyEpKW6rYCYiQ0yPgpkx5tq27ShjzDPGmAsGtiwRGSjG+Bgz5oc0NGxi9+7HvC6ncykpkJ8Pxx7rnq9aFb6+DNyi56BgJiJDTk87Zpe1bb8GfBO4cUCqEZGoyMqaR3r6bLZuvTO25zWbOhUSE93jyGDm97twduCAN3WJiAyQngYznzHm40CrtXYdED+ANYnIADPGUFz8dRobt7FvXwzPBxYfD9Onu8eRwQwgNVUdMxEZcnoazG4FzgfuMcYEgL8NXEkiEg3Z2ecRCIyN/cXNQ8OZkdeYgYKZiAxJPQ1mO6y1N1trq4DTgQcHsCYRiQJj/BQVXU9NzRvU1LzldTldCwUzdcxEZBjoaTB7Gj66CeAk4PGBKkhEomfkyC/h949g06bbsTbodTmdO+ccOPFEmD27/X4FMxEZgnoazELrt0yx1n4TSBmgekQkiuLi0hk//h6qqxezY8cvvC6nc4WFbrLZoqL2+xXMRGQI6mkwe9kY8y/gf9uuMUscwJpEJIpGjrySrKx5bNp0Ow0NWw//C7FCwUxEhqAeBTNr7fettTOttUuttQ3AyQNcl4hEiTGGiRMfIBhsYNeuX3ldTs8pmInIENTTCWZnGmNeM8YsNca8CIwf4LpEJIoCgRIyM89k9+5fx+61Zh0pmInIENTTocyfAp+z1p4EXN32XESGkJEjv0hj41aqq1/1upSeUTATkSGop8EsaK3dBmCt3Q4kDVxJIuKFnJxP4fePYPfux70upWdSU6GhAVpieOUCEZFe6mkwazTGjAMIbUVkaPH7k8jP/yzl5U/T2LjL63IOLzXVbbUsk4gMIT0NZjcCDxpjlgKPAtcPWEUi4pnRo2/F2ha2br3T61IOL6Vt1h4NZ4rIENJtMDPGPGmMeQL4HlABbAN2A9+KQm0iEmVJSeMYOfJKdu16OPanzgh1zBTMRGQIiTvM61+PShUiEjNKSr7N7t2Ps3Hj7Uyb9pTX5XRNwUxEhqBug5m1Nsb/k1lE+lsgMJqSkm+xZcv32LPnU+TnX+Z1SZ1TMBORIain15iJyDBSXPxN0tJOYP36a2ls3OF1OZ1TMBORIUjBTEQO4fPFMWXKbwkGG9i48Tavy+lcZ8Fs1Sq3rua2bd7UJCLSRwpmItKp5OTxjB59K3v3PsH+/f/0upxDdQxm770HM2fCySfDmDGwc6d3tYmIHCEFMxHp0ujRt5OQMIoNG27AWut1Oe11DGbf+Q6kpcGCBRAMwrp13tUmInKEFMxEpEtxcamMGTOf2trlVFb+zety2oucYPatt+DZZ+HWW+Hii93+rbp3SUQGHwUzEelWfv7nSEgoZPv2u7wupb2EBIiPdx2zBQsgOxtuuAFGj3av6zozERmEFMxEpFs+XwJFRTdSXf0KNTUrvC6nvdBC5suXw7x5bigzEICRI9UxE5FBScFMRA5r1Kir8fvT+de/TmTJknTKy//odUlOairs3g1lZTBpUnh/SUk4mD39NGza5E19IiK9pGAmIocVF5fO1KlPUFh4PfHxuWze/G2sDXpdlgtmb7/tHk+eHN5fXOyGMmtq4LLL4Oc/96Y+EZFeUjATkR7Jzv4k48f/N2PGzKe+/gP27XvO65JcMNu40T2ODGYlJS6Yvf02WOs6aiIig4CCmYj0Sm7uvxEIjGXbth95P4VG6M5Mnw/Gjw/vLymBhgZ46SX3XMFMRAYJBTMR6RWfL47Ro2+mtnY5Bw68520xKSluO2YMJCaG9xcXu+0f266F29HNslKVlfDaawNTn4hILymYiUivZWefD0BV1T+8LSTUMYscxgTXMQNYv95td+2C1tbOz/HAA3D66dDUNDA1ioj0gifBzBjztjHmHGPMJGPMImPMUmPM3RGvzzfGvNq2f5oXNYpI1wKBYpKSxlNdvcjbQg4XzAAKCqClBfbu7fwce/e612tqBqZGEZFeiHowM8ZcCoxoe7oQuMpaexJQaow5wRhzCpBvrT0NuAa4u/MziYiXMjJOp7r6VYLBFu+K6CqYZWRAerp7fL7r7nU5nFld7bb79/d3dSIivRbVYGaMSQM+D/wOiAMC1totbS//AZgDnAU8CWCtfR/IimaNItIzmZmn09paS23tcu+KCAWzyDnMQkLXmV1wgdseLpipYyYiMSDaHbOfAT8EgkAaUBHxWgWQCeQB5RH7W4wxh9RpjLnaGLPCGLOivLy848siMsAyMj4OQFWVh8OZWVlgzKEdM3A3BBQWwrHHuudd3ZmpjpmIxJCoBTNjzBXANmtt6D+vq4GMiEMycYFsf9vjkKDtZCZLa+3D1tpZ1tpZubm5A1O0iHQpISGH1NQZ7Nv3J6zt4sL6gXbllfDKK9DZvwE//jE89RTk5UFcXNcds6oqt1XHTERiQDQ7ZpcDU40xTwGXArcD04wxhW2vXwwsApa0vY4xZiqgCYhEYlRR0Y3U1b3Nli13eFPAiBFw2mmdvzZtGpx8spvjbNQoXWMmIoNCXLTeyFr7ydBjY8wdwDLc8OUzxphG4Dlr7QfGmLXAPGPMEqAWdwOAiMSgkSP/nerq19i69Yekp59EdvY5XpfUucLCww9lqmMmIjEgasEskrX2joinczq8FgSujWpBInLEJky4n5qaN1m37mqOO241cXFpXpd0qKIiWLXq0P3NzVBX5x6rYyYiMUATzIpIn/j9SUya9AiNjWVs3vwdr8vpXKhjZq2bs+yGG9yqAJFhTB0zEYkBCmYi0mcjRsxh1KivsmPHz6itXel1OYcqLIQDB1z4uv56+NnP4IknwsOYoI6ZiMQEBTMR6Rdjx95JfHwO69ff4P3i5h0VFbntySfDgw9CfDzs3Bm+IxPUMRORmKBgJiL9Ii5uBGPG3ElNzVLKy5/2upz2TjwRTjjBTavx3e/Cpz/t1s9Ux0xEYoyCmYj0m4KCK0lNncGmTd+gk+kHvVNcDMuWwT/+Ad//vhvajOyYZWerYyYiMUHBTET6jTF+iou/TkPDZqqq/uF1OV0bNQqammDTJve8pEQdMxGJCQpmItKvsrMvJC4uk927f+V1KV0bNcpt16xx25ISdcxEJCYomIlIv/L7A+TnX0F5+R9pbq46/C94oaDAbdesAb/fBTUFMxGJAQpmItLvRo68Emsb2bPnt16X0rlQx+zDDyEz0y3ttH+/m+dMRMRDCmYi0u/S0mYyYsTJbNnyXRoatnpdzqFCHbMDByAjA9LTobUVDh70tCwREQUzERkQkyf/GmtbWbPmcoLBFq/LaS852XXJINwxA90AICKeUzATkQGRlDSWiRMfoqbmDd5//wJaWmLsGq7QcGaoYwa6zkxEPKdgJiIDJj//s0yc+BCVlS/zzjufwNpWr0sKiwxm6piJSIxQMBORATVq1NVMnvxL6upWUlHxgtflhIWuM8vMVMdMRGKGgpmIDLi8vCtITCxix45feF1KmDpmIhKDFMxEZMD5fHEUFFxDVdXfqa9f63U5Tqhj1tk1Zps2wY03QkuM3bQgIkOegpmIRMWoUV/BmHi2bVuAjYX5wkIds8ihzFDH7Nln4b77wisDiIhEiYKZiERFQkI+RUU3sXv342zbtsDrcrq/K3PvXrddGyPdPREZNuK8LkBEho+xY39MY2MZmzd/k+TkieTmXuJdMbNmwVe/CqefDnFxbm6zUMdMwUxEPKKOmYhEjTE+Jk9+nNTUmWzYcCMtLXXeFRMIwC9+Abm57vmIEYd2zNat86Y2ERm2FMxEJKp8vngmTLifxsYytm270+tywtLTu+6YVVXpRgARiQoFMxGJuhEjTiQ//9/Zvv0e9u9/w+tynKwsqKhwjyODWW0tjB0LDz7oXW0iMmwomImIJ8aPv5dAoIT3378oNhY6LyqCsjL3eO9eSEpyHbTf/Q6qq2HjRk/LE5HhQcFMRDwRH5/FUUc9TzDYyJo1n/V+Co3iYti2DerqoL4eTjjB7b/3XrcNddNERAaQgpmIeCYlZTLjxt1FTc0/qaz8m7fFFBdDQ0N47rJTTnHb9evdtrLSm7pEZFhRMBMRT40c+UUSE4vZuvX73nbNiovddsUKt501CxIT3WO/Xx0zEYkKBTMR8ZTPl0Bx8TeoqVlGRcVfvCukYzArKIAJE1woO+MMBTMRiQoFMxHxXEHBl0hOnsKHH36B+nqP5g7rGMzy8uDcc+Ezn4Hx4zWUKSJRoWAmIp7z+RL52MdewBg/7733SRoatkW/iOxsdyfm6tXueW4u3HWXuyszK8vNZdbaGv26RGRYUTATkZiQlDSWo456jqamvaxceVz05zczxnXNgkFITXVLNIVkZ4O1btoMEZEBpGAmIjFjxIg5HHPMMvz+NN5773xaWvZHt4DQcGZeXvv92dluW1kJTz8Nt98e3bpEZNhQMBORmJKSMoVp056mpaWS7dvvje6bdxXMsrLctqLCDW0+8kh06xKRYUPBTERiTlraMeTmXkpZ2b00NZVH74170jHbutUNaQaD4debmmDPnqiUKCJDm4KZiMSk0tIf0NpazwcffI7m5ihNVXG4YFZR4YKZteEFzwHmz4dp09x+EZE+UDATkZiUkjKFiRMfpLp6MStWzIzOnZqHG8rcvDl8A0BVVfj1Z591oU03B4hIHymYiUjMGjXqambOfJ3m5nI2bfrmwL9hV8EsI8Pdtfmvf4X3hYLZrl3w3nvu8e7dA16iiAxtCmYiEtPS04+jqOgm9u79HbW1bw/sm40bBz//OXz2s+33+3yQmdk+mIUmnP3738P7FMxEpI8UzEQk5hUX3058fA4bNtyMtQM4yasxcN11h3bMwF1ntnVr+HmoY/byy27ZJlAwE5E+UzATkZgXFzeCsWMXsH//q2zceKs3RYRuAAiprHR3Zv7973D22W5fZ8Fs2TJ4/fWBr09EhgQFMxEZFAoKrqKw8AbKyhZSVnZ/9AsI3QBQVOS2VVWwZg3s3Quf/jQkJHQezG6/HW66KXp1isigpmAmIoPG+PH3kJ19ARs33hT9JZtCHbNJkyAQcB2zjRvdvqOOgpEjOw9m5eWwc2f06hSRQU3BTEQGDWP8TJ78axITi1mz5jM0Ne2N3puHgllJSXhR8x073L7CQhfMOptktrLS7dcC6CLSAwpmIjKoxMdnMG3aMzQ3V/Duu2fQ1LQvOm8cGsosKXF3aFZWumDm97ubBTrrmFnr5jdrbXWdMxGRw1AwE5FBJy1tJkcd9RwHD65n1aozaWmpG/g3jeyYZWaGO2YFBS6c5ecfGszq6qClxT3etWvgaxSRQU/BTEQGpaysM5g27Y/U1a1i3bqvYAd6OaTIjlnkUGZhods/cqTrikUOWVZELCWlYCYiPaBgJiKDVnb2uYwZ80P27n2KHTsG+E7Ns8+G//ovmDMnPJS5c2f7YBYMth+yDE1CCwpmItIjCmYiMqgVF99OdvZ5bNp0G/X16wfujTIz4a67IDGx644ZtB/OjOyY6c5MEemBqAUzY0yGMeYpY8xiY8xrxpgxxphJxphFxpilxpi7I46db4x5tW3/tGjVKCKDjzE+Jk58CGMSWbv2K1gbHPg3zcx014/t3w+jRrl9oWC2Ywfcdx/s29d1x+wnP4HLLx/4OkVk0ImL4nslAzdba3caYz4J3AqMBa6y1m4xxvzeGHMCkADkW2tPM8YcBdwNzItinSIyyCQmjmLcuP9m3bqv8O67ZzBy5JXk5X0Gny9+YN4wMzP8ONQxy89325/+FBYtchPOhq57y8lpH8wWLWq/7qaISJuodcystTuttaFefhXQCASstVva9v0BmAOcBTzZ9jvvA1mdnc8Yc7UxZoUxZkW5bkMXGfYKCq5izJgf09CwhQ8//DzLlx9FZeXLA/NmWRH/LHUMZosWue22beGO2bRp7YPZzp3haTRERCJE/RozY0whrlt2DxBxAQYVQCaQB0QmrRZjzCF1WmsfttbOstbOys3NHciSRWQQMMZQUvJ1TjhhI0cd9SwAq1dfSnNzdf+/WWcds9RU9xOybZsLX6mp7k7OyGvMdu4Mz3EmIhIhqsHMGHMe8F3gK0AlkBHxciYukO1vexwStFG5aEREhgJjDDk5FzB16lO0ttayc+eD/f8mnXXMwF1vNm4cnHxyuGOWne3mOtu924WxgwfdjQOgSWdF5BDRvPj/aOB8a+011toKa+1BILGtgwZwMbAIWAJc2vY7U4GyaNUoIkNHWtpMsrLOoaxsIa2tB/v35KGOWXp6+y7Zww/DM8/A2LGwdavriGVluWDW3OyeR961uTeKS0qJyKAQzYv/zwFOMcYsbnu+DbgZeMYY0wg8Z639wBizFphnjFkC1ALXRLFGERlCiou/wTvvnMb27f9Nael3+u/EoWAW2S0DOO200Bu7uzPz813HLHTn5q5dUFMTPl4dMxHpIGrBzFp7F3BXJy/N6XBcELg2KkWJyJA2YsQp5OZ+hi1bvkt8fBaFhf/ZPyfuKpiFFBe7yWbXrIHzznMdM3DXlkUGM3XMRKSDaHbMRESiyhjDlCm/wdpG1q+/DmPiGDWqH5rwcXFuGLO7YAZQXx++xgxcx2z//vBx6piJSAcKZiIypPl88Uyd+r+sXn0J69b9B8bEUVBwVd9P/OCDbhqMzoSCGYSHMo2BLVugocHNcZaW1vOO2c6d4YXSRWRIUzATkSHP50tg2rRneP/9i1i79iuAn4KCL/btpN3N3D96dPhxVhYkJcGUKbBiRfhmgJSUcMesuRniu5kM93Ofc0Hu2Wf7VrOIxDytlSkiw4LPl8i0aX8kM/MM1q69kl27Hh+4N0tNDU+pkZ3ttscdB8uXu5sCRo2C3FzXMXv3XRe6/vCHrs+3ZYvW2hQZJhTMRGTY8PsDHHXUn8nMPJ21a7/E1q0LaG2tH5g3Cw1nhgLacce5IPb22y6Y5eW5jtmSJdDYCF/8Inz4Yefn2rev/bVpIjJkKZiJyLDi9yfzsY+9QF7eZWze/A2WLElhxYpZtLYe6N83Kilx28iOGUB19aEdsxEj3HBnZ8OjjY1QW+t+T0SGPAUzERl2fL5Epkz5HdOm/ZHi4m9RV7eSsrL7+vdNOnbMpk8PX0cW6phVVsLKlXDssfC1r7mFzQ92mAw3dB3a/v3hRdFFZMhSMBORYckYH7m5FzF27A/Jzr6Abdt+QnNzP65dOW4c+HwugAEkJsLRR7vHBQWuYwbwzjtu/9ix7vnWrW67YoWbCy0UzJqa3B2dIjKkKZiJyLA3ZsydtLbWsn7912hpqeufk375y/Daa+0XPA8NZ4Y6ZuC6YNOnQ2mpe75li5uY9rjj4M9/bj/Xma4zExnyFMxEZNhLTT2KkpJvs3fvkyxfPpUPPvgi27ffi7WtR37SlBQ46aT2+0480W1LS8PBDA4NZqtWucfr17cPZrrOTGTIUzATEQHGjPkBM2YsISlpHFVV/8fGjbewe/ev+/dNLr8c/vlPmDAhPJTp98PUqW54Mz7eBbO1a91r27b1rGP2wQfh9TlFZFBTMBMRaZORcTIzZrzCnDnbSU8/iU2bvkFLS83hf7Gn/H6YPds9DnXMJk9215/5fO5Ozi1bwtNmbN/es47Zm2+6Y1ev7r9aRcQTCmYiIh0YY5gw4T6am8vZsOFmgsHm/n+TzEwX1KZPD+8rLT2yjllZmdvu29f/dYpIVCmYiYh0Ii3tWIqKbmL37l+yYsVM6ure7d838Pngxz9202SElJbCpk2wbp17HuqYhabcqK52C6P/5S/tz6VgJjJkKJiJiHRh/Ph7OOqoZ2lpqeKddz5BXd27BINNfbspINJ//Vd4aBPcUGZ5ORw44B5XVroO2vjx7vX9++GJJ+C889yNASEKZiJDhoKZiEg3cnIuYObMJfj9KaxceTyvvZbEW29N6d85z0JCd2YCnHmm265e7fb7/a5jFprnLNRVAwUzkSFEwUxE5DCSksYyY8YrFBR8mdGjb6WhYQsffvglbH/PxN9ZMGtudndwjhjhOmahOy83bgwfG9qnYCYy6MV5XYCIyGCQlDSOiRN/AUBi4ig2bLiRrVvvpLT02/33JqFglpYGxx8f3p+bCxkZLpiFbgYIBbOGhnAgUzATGfQUzEREeqmw8Hpqat5iy5bvYG0zpaV3YIzp+4lDc5lNngyFhWCMWxkg1DGrrj60YxY5d5mCmcigp6FMEZFeMsYwZcr/Y+TIK9m69QcsXz6VnTsf6fvQZmj6jBNOcAFt1Ci3P7Jj1jGYha4vGzNGwUxkCFAwExE5Asb4mTTpESZP/g1+fxrr1l3N6tWX0Nxc2bcTL14M99zjHo8e7bahjtmuXVBVBXFxsHmzW+Q8FMxmzHDBLDIcrl3b/rmIxDwFMxGRI2SMj5EjP8cxx7zJuHH3sm/fcyxdmsuKFTPZtetxrA32/qQpKZCQ4B4XF7ttKJht2uSez5oFjY2uexYKZtOnuxsFamvd85Ur3ZDoyy/37Y8UkahSMBMR6SNjDKNH38Sxx66gtPS7gJ+1a7/E22/PpqFh25GfOLJjlpHhOmQAp57qtps2uWCWkRG+cSA0nPl//+e2K1Yc+fuLSNQpmImI9JO0tBmUln6PY49dzpQpv6W+fh1vv30CtbUrj+yE550HF14IOTmuYxYSCmYbN7pgVlTkjoFwMHvtNbdds8Ztf/tb+Otfj6wOEYkaBTMRkX5mjCE//wqOOWYpxiTwr3+dyr59z/f+RHPnwp//7JZvysgI7589211n1lUwa22F1193z9escdeZ3XQT/OQnffzLRGSgKZiJiAyQlJRpHHPMMpKTp/D++59i3br/5ODBTUd2slDHLDnZrZ1ZUgLLl7slmwoLw8GsvBxWrYKaGhfYPvzQLd+0b1/4GjURiVkKZiIiAygxsYCZM1+loODL7Nr1CG++OZGNG2+jtfVA704U6piF5jebMAH+/ncXuGbMaN8xCw1jfvnLbgLaJ590z3fscM9FJGYpmImIDDC/P4VJkx5i9uzNjBz5RbZvv5ulS3NZufJ49u79fc9OEuqYFRa67V13wS9/CR98AP/5n5Ce7oY3Q8GstBTOPtsd+9hjbmut67CJSMxSMBMRiZLExEImT36UmTOXMmrUfxAMNrBmzb9RVnbf4Sen7RjMPvYxuPJKNyWGMe4nJwe2bYN//ANOOw2mTHHHbt0a/v3I4cw1a9xcZyISMxTMRESibMSIExk//l6OOeYtcnI+xYYNN/Kvf53Enj1PUl+/tvP5zyKHMruSkwPPPOOWbrrqKhfGQsdfeqnbbtrk5kC75RYX7j7+cfdcRGKCgpmIiEf8/gBTp/6eCRPup7FxBx98cDlvvTWZZcvGsGXL9zlw4AOstTQ17SWYnQmJiTBpUtcnzMmBpiY45hg4+WS3b9o0t73wQnfjwKZN8MADcO+9bqhz1y43lYaIxAQtYi4i4iGfL47Cwv+koOBq6ure5cCBVezd+79s2fJ9tmy5A58vmWCwnpSUo5ix6p/Ej/1Y1ycL3QBwww1uaBNcMHv5ZZgzB8aOdcFs9WqYOhX+8hc49li4+2740pfctBwi4ikFMxGRGODzxZOePov09FkUFFxJY+MO9u17jvr6D4iPz2Hr1jt5P+56PsaLxJHa+UkmTXLTaHzmM+F9N97o5j3LyXHBbM0aN/fZV77iwtvtt8Nll8ETT8DnPheVv1VEumYOe8HpIDBr1iy7QsuOiMgQtnfv06xZcxlxcSMoKPgypaV34PentD+otdVdL5ac3PlJbroJFi50j59/3q0s0NICJ50E774LL7wAn/hE+GYCERkQxpiV1tpZnb2mvrWIyCCQl/dvzJz5BllZ57B9+728/fZsqqpeoa5uFY2NO7G2Ffz+rkMZuI4ZuONOO809jouDF1903bYzz3SvFRfDo4+60AZugtqnnnKPd+1yx/7znwP3x4oMYxrKFBEZJEaMmM2IEbMZOfJK1qz5LO+++4mPXvP5kikuvo3Ro2/D70/q/ATjxrnt7NmQlhben5XlFj3/n/9xC6W/9JIb6nz/fddhu+46d53aMcfAH/8I69a57tqcOQP3x4oMUwpmIiKDTFbWmRx//Bpqa5cTDDbQ1FROdfUitmy5g927f8348QvJzj4f03E4MtQxO+OMQ0+amwvf+Y57/N3vujnS/ud/4KKLXCgDdzfniy+6x2+9deg5Fi1yNxI8+SRkZvbPHysyzOgaMxGRIaKq6hXWr7+O+vo1pKQcTXb2PBITS0hIGEl6+vEkJhS4sPVv/wbZ2d2fbMMGN2SZng4HDrj5zl55BZqb3Y0ELS1QWRm+Fm3zZneHZ1UVPPyw67iJSKd0jZmIyDCQmflxZs16hwkTfkFc3Ai2bbuL9euvZfXqi/jnPwt5860pbD5nF01prYc/2fjxLsBVV7u7PL/3PRfKkpPhW99y+zdsgFdfdSHszDPdkk9FRfD7Hi4zJSKHUMdMRGSIam1toKWlmoaGLdTULKOi4nmqqxcTF5fJmDE/JBAoJSlpPMnJ4zs/werVcP758Kc/wdFHw1lnudUCvvhFmD4dHnnETbfR0uIWVV+wwHXVfvITd5NAbm74XHV1rps2enRU/naRWNZdx0zBTERkGDlwYA0ffngltbVvfrQvNXUmWVnnkJ5+Iunps0lIyOn+JC0tbogzPR327IElS8IrDbz7LsyYAQ89BFdf7fatXu1WHti7193hmZ8/MH+cyCChYCYiIh+xtpUDB96ntfUANTVvUl7+NLW1K7DWTY+RlDSRESNO/CioJSVNwO8PtD/JySfD0qVwwglu6ozQtWbWumvTdu2CQNvv1Na6tT4rKlxYu+Yat9JAWZkLaW+8Aamp7nc1f5oMA90FM92VKSIyzBjjJzV1OuAWVB89+iZaW+uprV3B/v1vUFPzBhUVL7B79+Mf/U4gMJbMzDMIBEqwtpXco9JJWQrcemv7MGWMG8p86ik3DQdAfDzcdhv86EfuxoCnn4aEBDj3XPj1r+G+++DTn3bXqd10k1utIKShwa0RqsAmw4Q6ZiIicghrLQcPbqC29i0OHtxIbe3bVFe/QmtrDQDJm2Hk36D85mPJyj2XQGAMgUAJgUApiYmj8fkSDj3pnj1uLrX0dHfTwIQJbohz8WIoLYVVq9xxCxfCwYNuLc833nDTeNxxB7z3nptb7bLLFNRkUNNQpoiI9Jm1rW3DnYb6+rVUVf0fe/b8lrq6d4BgxJGGhIQCAoFSkpMnk5LyMRITC0lIyCNhQw3xeWOJGz0FY3wubE2f7oYx//AH1z177TV3mhkzXLftvffgzTdh3jzYsQMuvdSFtawsKCxsH9I0HCqDgIKZiIgMmGCwmcbGMhoattLQsIXGRrc9eHAz9fWraW7ed8jvGBNHfHwu8fF5FP6uHl/yCOquPJXExnRSl+yGk2fjL55Gwu5mEqd/AuP3u3VAv/pVuP9+t0IBwOTJbo61+nrXcXv/fbjiCjeFx3e+44ZBn3wSRowIv/n+/XDPPW5ZqtNPj9KnJBI2KIOZMWY+cCruOrirrbWruzpWwUxEJDZZa2lu3kdT026am/fS1LT3o21T054O+/YQDNYfco4xj0DJE1D2lSz2/sdk0rYHSN7iI7HCR+rfN5LwwS5sSoDWMYVQXEj803/HtLZiM0dA7QGYNhXzhX93NyHU1LigtmuXu87tySfd0OrevXDqqW7t0PXr3Zqhqalu6aqCgvCNDCL9YNAFM2PMKcDnrbVXG2OOAu6y1s7r6ngFMxGRoaG19cCh4a1uJ/GLllN9UgpNwX00N+9pO2Yf7YdQnbQPIXsZ7LgIUtfCtDsg7mDb+QOG+gmJ7PyPIop+sZuUNXWHrSmY6Kfx6AL8VQeJ21FD88R8WoqzMPjAGvD5sKlJ2LQUSE/FpqdAIIm49Tvx7ashOG40wZJCyMnCt6ca394qSE3D5udBaQnG+vDV1QMG6/OD8bkOoc8HvtDW54JiVpYb3jU+t+SW8bkfwADUHwR/nFvZISHR7Qta92Np9zsmdF5jwj+ROt7UIf1mMAaz+cA/rLWvtD1fZq2d3dXxCmYiIsOPtUFaWw/Q2lpLS0sNra01tLTUEAweaNvvfmx9Na0N+2lJbKaVg7S2HiAYPADV1WQ8u42GoniacgypK2uwJkj9aB/Qiu9AM74DLaRsbCbtvRaasqAh35K6CRIqaEtCgAV/PcTVg78hXF9rAJoyILAXzKH5cciwkZmtY36LvPyvi/2HPO/qd7o5rtPnR6j2MzPJeOzt/jlZFwbjdBl5QHnE8xZjjM9a+9FX2xhzNdA2eyF1xpi1UagrBzj0Ygk5Uvo8+58+0/6nz7T/DY/PtAHYHbV38+4ztV08Hqwe/xc8bmBgP9OSrl6I1WC2H8iMeB6MDGUA1tqHgYejWZQxZkVXCVd6T59n/9Nn2v/0mfY/fab9T59p//PqM43VRcyXAJcCGGOmAmXeliMiIiIy8GK1Y/YXYJ4xZglQC1zjcT0iIiIiAy4mg1nbsOW1XtfRiagOnQ4D+jz7nz7T/qfPtP/pM+1/+kz7nyefaUzelSkiIiIyHMXqNWYiIiIiw46CmYiIiEiMUDDrAWPMfGPMq8aYpcaYaV7XM5gZY94zxixu+7ncGDPJGLOo7bO92+v6BgNjTK4x5s62iZjp6jPU97bnOvlMP2+MWdP2PX054jh9pj1gjMkwxjzV9vm9ZowZo+9p33Txmep72gfGmARjzPNtn9+rxpjCWPiexuTF/7GkbXmofGvtaW3LQ90NdLk8lBzWHmvtGaEnxpgXgaustVuMMb83xpxgrX3Tw/oGg3uADUBy2/OFdPgMgQT0ve2Njp9pBvANa+2zoQP0b0GvJAM3W2t3GmM+CdwKjEXf077o7DP9EH1P+6IF+Iy1tt4Y8zng34FT8Ph7qo7Z4Z0FPAlgrX0fyPK2nEEvcvWGOCBgrd3StusPwBwvihpMrLVfAF6Dbj9DfW97IfIzbZMBVHU4TJ9pD1lrd1prd7Y9rQIa0fe0Tzr5TA+g72mfWGuD1tr6tqcTgPeIge+pgtnhdbo8lFfFDGbGmBRgXFsb/mmgAKiIOKSC9is+yOHl0vlnqO9t38QBdxljlrQt/wb6THvNGFOI6+zcg76n/SLiM12Ivqd9Zoz5L2PMemAW8DYx8D3VUObhHXZ5KOkZa+0BYByAMeZM4F7cf/GFZNL+yy+HV03nn2ES+t4eMWvt94DvGWOSgWeNMUvRvwW9Yow5Dzgf+ApQj76nfRb5mVprKwB9T/vIWns3cLcx5ly6/v+kqH5PlaIPT8tD9RNjjD/iaTluudvEtv8CBLgYWBT1wgYxa+1BOv8M9b3tg7YhYoCDuNVHLPpMe8wYczRwvrX2Gmtthb6nfdfxM23bp+9pHxhj0owxpu3pNsBPDHxP1TE7PC0P1X/GG2N+BTS1/VwLZAPPGGMageestR94WeAgdTMdPkNjzFr0ve2LHxtjjsf9G/kna+0aY8yH6DPtqXOAU4wxi9ueb0Pf077q7DPdo+9pn0wGFrZ9Jw8C1wE5ePw91cz/IiIiIjFCQ5kiIiIiMULBTERERCRGKJiJiIiIxAgFMxEREZEYoWAmIiIiEiMUzERE+sAYs8zrGkRk6FAwExEREYkRCmYiMmwYY+4wxrzatl7rscaYxcaYrxtj/mGMecsYc2zbcScaY15pe/3vxpixbftnGmP+r23/f7edNs4Y86Ax5k1jzB8iZhIXEek1zfwvIsOCMeYMIMNae5oxJgv4f20vrbHWLjDGjAceBM4Efgaca60tN8YcB9yFW5LlIeBia21ZxCLGE4DzrLW7jTHPAUcD70bxTxORIUTBTESGi2OA0yOWtPEDrcDfAay1G4wxqcaYXGCntba8bf9yY0yhMSYH2G2tLWvbH1rEeK21dnfb4w9ov9ixiEivaChTRIaLdcDT1tq51tq5wNlt+48HaOuM7QD2AaONMdlt+48FNgKVwJiI/fFtvx8kTGvciUifqGMmIsPFs8A5xpjXcQsRP9a2/2xjzLcBA3zFWmuNMTcCzxpjmoBq4KvW2qAx5ibgBWNMA/AK8INo/xEiMrRpEXMRGbbahjXPsdY2eF2LiAhoKFNEREQkZqhjJiIiIhIj1DETERERiREKZiIiIiIxQsFMREREJEYomImIiIjECAUzERERkRjx/wHwEmD1Crx7yQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "# plt.figure(figsize=(6,4)) # ERROR\n",
    "fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "# 왼쪽 y 축 설정\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 1000]) # 값을 반영하여 변경 ★\n",
    "\n",
    "# 축 레이블 설정\n",
    "loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "loss_ax.set_ylabel('loss')   # 오차\n",
    "\n",
    "loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "\n",
    "plt.show()\n",
    "# train loss: 하강하면 훈련이 정상적으로 진행되고 있음\n",
    "# val loss: 하강하면 훈련되지 않은 데이터를 대상으로 한 테스트도 정상적으로 진행됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 750650.1553 - val_loss: 3392220.2500\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1144247.0147 - val_loss: 3383901.5000\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 816991.4228 - val_loss: 3376492.5000\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 1189174.500 - 0s 4ms/step - loss: 1115055.4449 - val_loss: 3368112.0000\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 930029.4375 - val_loss: 3359763.0000\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 638801.2390 - val_loss: 3352417.0000\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 909333.4908 - val_loss: 3343488.5000\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1414191.4706 - val_loss: 3334043.2500\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1120765.6176 - val_loss: 3326244.0000\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1283233.2243 - val_loss: 3316963.0000\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1168822.6985 - val_loss: 3308205.5000\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 868061.3658 - val_loss: 3299004.0000\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 988208.2607 - val_loss: 3289188.7500\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 711971.6204 - val_loss: 3280229.0000\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 862730.4476 - val_loss: 3269877.5000\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 978293.7978 - val_loss: 3259453.0000\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 976922.1778 - val_loss: 3248889.0000\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 700157.6360 - val_loss: 3239606.0000\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1075434.2169 - val_loss: 3227828.5000\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 548515.5864 - val_loss: 3218199.5000\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 793449.3272 - val_loss: 3205898.5000\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 899333.4908 - val_loss: 3193922.2500\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 683655.8015 - val_loss: 3183200.2500\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 836484.4559 - val_loss: 3169747.5000\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 756202.6002 - val_loss: 3157862.0000\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 625362.8327 - val_loss: 3146087.0000\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 624557.5864 - val_loss: 3133346.0000\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 599218.4403 - val_loss: 3120411.5000\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1019794.7794 - val_loss: 3105993.0000\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 736455.4798 - val_loss: 3093317.5000\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 747248.2353 - val_loss: 3080479.5000\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 793749.1121 - val_loss: 3064939.7500\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 889269.4890 - val_loss: 3050617.5000\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 694614.7776 - val_loss: 3036825.0000\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 813601.7518 - val_loss: 3021845.7500\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 771033.6985 - val_loss: 3006446.0000\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 835640.6342 - val_loss: 2990799.5000\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 773175.0312 - val_loss: 2975344.0000\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1075083.8787 - val_loss: 2958908.5000\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 685222.8493 - val_loss: 2944255.0000\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 927137.8787 - val_loss: 2926687.5000\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 910541.8640 - val_loss: 2910113.5000\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 852149.9265 - val_loss: 2893129.7500\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 683591.5133 - val_loss: 2876315.2500\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 779747.7445 - val_loss: 2858327.7500\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 862081.3787 - val_loss: 2840549.0000\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 767288.2868 - val_loss: 2822718.0000\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1080613.3860 - val_loss: 2803176.5000\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 797669.2879 - val_loss: 2785232.5000\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 923205.9272 - val_loss: 2765438.0000\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1078643.6029 - val_loss: 2746259.5000\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 737773.6213 - val_loss: 2727636.5000\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 544649.4890 - val_loss: 2710954.5000\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 628539.6903 - val_loss: 2690558.5000\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 524836.5294 - val_loss: 2670723.0000\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 970186.0588 - val_loss: 2648981.2500\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 992817.3713 - val_loss: 2627272.2500\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 988412.0662 - val_loss: 2606971.5000\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 692368.5919 - val_loss: 2588582.0000\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 998724.2132 - val_loss: 2565801.0000\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 697423.9614 - val_loss: 2545861.2500\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 698178.2868 - val_loss: 2525366.0000\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 678906.1820 - val_loss: 2503573.2500\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 657139.2500 - val_loss: 2481782.2500\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 760272.1011 - val_loss: 2460047.2500\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 736906.9926 - val_loss: 2436878.7500\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 629951.7463 - val_loss: 2416092.0000\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 775452.9853 - val_loss: 2394120.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 662456.5882 - val_loss: 2373663.0000\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 474973.6296 - val_loss: 2352043.0000\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 852283.2537 - val_loss: 2327010.2500\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 603945.5800 - val_loss: 2305157.0000\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 764376.4816 - val_loss: 2281623.5000\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 537927.5386 - val_loss: 2260781.0000\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 647609.7610 - val_loss: 2237475.7500\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 644223.1710 - val_loss: 2215438.0000\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 879732.0441 - val_loss: 2189930.5000\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 441722.8134 - val_loss: 2169940.5000\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 415072.6733 - val_loss: 2148516.0000\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 484932.6397 - val_loss: 2124647.7500\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 468096.7767 - val_loss: 2101572.7500\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 411297.8642 - val_loss: 2078685.7500\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 436285.4504 - val_loss: 2055692.0000\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 653015.0055 - val_loss: 2030699.0000\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 436759.6489 - val_loss: 2008431.3750\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 516753.1967 - val_loss: 1984584.6250\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 316287.2827 - val_loss: 1962900.3750\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 459261.0873 - val_loss: 1936853.0000\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 440142.1176 - val_loss: 1914313.8750\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 548654.4430 - val_loss: 1890712.5000\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 786108.1103 - val_loss: 1864843.7500\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 497522.8252 - val_loss: 1842830.5000\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 591930.5165 - val_loss: 1819805.5000\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 416802.3603 - val_loss: 1799651.5000\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 475166.0368 - val_loss: 1773659.2500\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 508360.2785 - val_loss: 1750010.7500\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 538076.8585 - val_loss: 1727252.8750\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 455482.5492 - val_loss: 1704570.7500\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 429779.2610 - val_loss: 1681522.0000\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 685854.2077 - val_loss: 1656137.8750\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 405467.5653 - val_loss: 1634605.2500\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 333016.9181 - val_loss: 1614196.2500\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 534152.4798 - val_loss: 1588120.1250\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 492888.1213 - val_loss: 1566357.5000\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 576268.0680 - val_loss: 1542710.8750\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 587077.4154 - val_loss: 1518074.8750\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 396023.5897 - val_loss: 1498051.7500\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 349951.6783 - val_loss: 1475535.1250\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 423097.8051 - val_loss: 1451743.3750\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 374516.9058 - val_loss: 1429549.7500\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 395438.7022 - val_loss: 1407831.1250\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 376927.5301 - val_loss: 1384531.3750\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 338035.0384 - val_loss: 1361687.1250\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 333160.4007 - val_loss: 1341362.8750\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 385943.7206 - val_loss: 1318324.5000\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 344187.4917 - val_loss: 1296069.6250\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 402592.3640 - val_loss: 1273657.0000\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 273898.1075 - val_loss: 1252942.0000\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 353436.0607 - val_loss: 1230952.5000\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 333317.3493 - val_loss: 1209411.6250\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 327657.8952 - val_loss: 1188045.1250\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 208082.3190 - val_loss: 1168465.5000\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 317915.4669 - val_loss: 1145950.5000\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 383981.9246 - val_loss: 1123795.8750\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 354962.0487 - val_loss: 1102935.2500\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 305372.1002 - val_loss: 1082348.8750\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 252599.8529 - val_loss: 1061633.2500\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 314643.8006 - val_loss: 1041396.5625\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 282032.3561 - val_loss: 1020635.2500\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 313025.1379 - val_loss: 1000106.8125\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 269150.9357 - val_loss: 980946.8750\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 325727.4982 - val_loss: 959868.8125\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 310373.9807 - val_loss: 939780.4375\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 188203.9824 - val_loss: 922676.6250\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 238311.2910 - val_loss: 902066.2500\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 183423.5510 - val_loss: 884225.5000\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 306243.2518 - val_loss: 862527.3750\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 279810.2592 - val_loss: 844277.5000\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 184296.4278 - val_loss: 827240.3125\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 209396.4516 - val_loss: 807833.2500\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 144582.8414 - val_loss: 790998.6250\n",
      "Epoch 142/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 244364.9706 - val_loss: 771745.4375\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 259161.3631 - val_loss: 752930.1250\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 126974.8826 - val_loss: 738562.2500\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 185018.3676 - val_loss: 720386.0000\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 247347.0579 - val_loss: 702097.5625\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 190638.0625 - val_loss: 685990.2500\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 151392.0308 - val_loss: 670341.8125\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 126758.9428 - val_loss: 654173.7500\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 131764.3286 - val_loss: 637967.0000\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 121576.8421 - val_loss: 621753.8125\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 129685.9577 - val_loss: 605692.2500\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 194691.5506 - val_loss: 589189.3750\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 118952.3867 - val_loss: 574884.9375\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 156636.3873 - val_loss: 558195.7500\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 102221.3127 - val_loss: 544318.1250\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 113981.4113 - val_loss: 530372.3125\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 126443.3608 - val_loss: 516383.7812\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 128958.2902 - val_loss: 500894.0625\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 166965.9812 - val_loss: 486813.9375\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 111941.8957 - val_loss: 474190.4688\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 98668.0960 - val_loss: 461523.8125\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 101980.8135 - val_loss: 447007.3438\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 98901.0604 - val_loss: 434866.0625\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 102475.5018 - val_loss: 421563.0938\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 138661.1213 - val_loss: 408248.8125\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 64348.4912 - val_loss: 397578.7500\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 119358.6089 - val_loss: 385196.3125\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 70566.7564 - val_loss: 374870.0625\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 95624.1444 - val_loss: 361757.4062\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 41267.8089 - val_loss: 352736.9688\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 89433.6282 - val_loss: 340125.5625\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 62574.2044 - val_loss: 329214.2500\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 58608.3099 - val_loss: 319139.8438\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 82869.4019 - val_loss: 308714.5000\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 55497.2676 - val_loss: 299147.5000\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 1240.23 - 0s 4ms/step - loss: 54629.4704 - val_loss: 289394.9688\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 85137.1066 - val_loss: 279046.4062\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49481.7968 - val_loss: 270336.0938\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 45812.2058 - val_loss: 261689.8438\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 58141.3511 - val_loss: 252094.3750\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52960.6677 - val_loss: 243795.3438\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 81726.3971 - val_loss: 234799.7656\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 56592.4108 - val_loss: 227189.0781\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 55900.3199 - val_loss: 219450.9531\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49259.7838 - val_loss: 211304.4531\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 56926.7884 - val_loss: 203951.7188\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 51198.8272 - val_loss: 196297.9062\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 32773.2977 - val_loss: 189700.3594\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 28470.8009 - val_loss: 183067.4219\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 39040.1954 - val_loss: 176035.8750\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35608.5617 - val_loss: 169718.9219\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 40479.9401 - val_loss: 162990.5625\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 40751.6953 - val_loss: 157119.8750\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 35596.4743 - val_loss: 151111.5469\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 31850.3563 - val_loss: 145363.9531\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 37980.7904 - val_loss: 139968.9062\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 17238.4618 - val_loss: 134894.0000\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 25509.4279 - val_loss: 129436.9531\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 30488.5211 - val_loss: 124172.5156\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 24511.2029 - val_loss: 119377.2422\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 21711.8698 - val_loss: 114467.1562\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 27049.3741 - val_loss: 109938.8438\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 23671.1267 - val_loss: 105526.0234\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - ETA: 0s - loss: 19134.906 - 0s 4ms/step - loss: 20948.6693 - val_loss: 101319.8438\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 26092.8832 - val_loss: 97059.3438\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 18116.6310 - val_loss: 93164.6797\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 16403.9087 - val_loss: 89607.7109\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 17277.7016 - val_loss: 85849.3906\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 15706.5820 - val_loss: 82204.4219\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12783.6650 - val_loss: 78975.0391\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 18637.8096 - val_loss: 75404.9922\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 11187.9380 - val_loss: 72588.5938\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 17780.9131 - val_loss: 69231.8906\n",
      "Epoch 215/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 17679.7745 - val_loss: 66428.0469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 9902.0524 - val_loss: 63757.8125\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 10889.0934 - val_loss: 61026.7188\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 11734.5258 - val_loss: 58481.1523\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8447.5524 - val_loss: 56071.4688\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 12010.8618 - val_loss: 53516.0117\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8793.0544 - val_loss: 51344.0039\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 15935.7549 - val_loss: 48957.6406\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 8426.8721 - val_loss: 47101.2148\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7275.5630 - val_loss: 45096.0469\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7696.9519 - val_loss: 43108.2969\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7914.4735 - val_loss: 41228.9531\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 9693.0853 - val_loss: 39433.7031\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7312.8985 - val_loss: 37758.0469\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6880.1505 - val_loss: 36282.5078\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3427.1920 - val_loss: 34900.0703\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4889.6297 - val_loss: 33280.2500\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3868.6603 - val_loss: 31944.1797\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5090.4003 - val_loss: 30583.8320\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5004.0135 - val_loss: 29211.7754\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5278.0424 - val_loss: 27942.5020\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5371.0680 - val_loss: 26721.6016\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4563.6909 - val_loss: 25693.5430\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3981.1400 - val_loss: 24738.8496\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3538.7799 - val_loss: 23621.6426\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5697.9293 - val_loss: 22581.4102\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3282.1150 - val_loss: 21669.2246\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3361.6745 - val_loss: 20887.0508\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 4204.6197 - val_loss: 20022.7734\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5105.8826 - val_loss: 19163.6367\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2482.2782 - val_loss: 18530.0098\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3247.6884 - val_loss: 17815.8477\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2355.1429 - val_loss: 17111.4746\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2013.3989 - val_loss: 16489.3652\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2586.2827 - val_loss: 15804.4297\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2643.6270 - val_loss: 15249.8438\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3188.5310 - val_loss: 14647.7188\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2696.3454 - val_loss: 14171.6152\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2483.0979 - val_loss: 13651.1719\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2076.7552 - val_loss: 13046.8486\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2443.3674 - val_loss: 12578.8838\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2168.8075 - val_loss: 12183.7832\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2080.0652 - val_loss: 11884.4619\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3367.8833 - val_loss: 11427.2344\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2523.9050 - val_loss: 10995.7158\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2800.3933 - val_loss: 10680.4521\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3260.8062 - val_loss: 10299.5889\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2138.4712 - val_loss: 10037.0400\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3355.4543 - val_loss: 9673.9014\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1729.3532 - val_loss: 9412.3555\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2711.4497 - val_loss: 9174.8291\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1730.3529 - val_loss: 8916.0967\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1895.1096 - val_loss: 8661.2461\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2655.9784 - val_loss: 8390.1006\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1844.1682 - val_loss: 8177.4492\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1724.6800 - val_loss: 7998.1963\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2280.2363 - val_loss: 7787.0322\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2079.7288 - val_loss: 7601.9570\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1519.8859 - val_loss: 7435.3154\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1721.6301 - val_loss: 7268.9326\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1442.7555 - val_loss: 7085.5801\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2079.7187 - val_loss: 6916.3711\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2065.8731 - val_loss: 6856.5127\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1938.8205 - val_loss: 6676.7568\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1741.4268 - val_loss: 6514.6309\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2662.5771 - val_loss: 6407.6533\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1755.6472 - val_loss: 6297.1460\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1164.3001 - val_loss: 6184.0288\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1610.6100 - val_loss: 6092.7490\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2728.2809 - val_loss: 5939.5923\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2360.6737 - val_loss: 5912.4722\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1862.8503 - val_loss: 5749.0142\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1826.5353 - val_loss: 5650.1035\n",
      "Epoch 288/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1464.8958 - val_loss: 5549.7251\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1996.4514 - val_loss: 5552.3911\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 1273.7878 - val_loss: 5399.6245\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2281.1425 - val_loss: 5404.1904\n",
      "Epoch 292/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 2067.6073 - val_loss: 5333.4668\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1680.4601 - val_loss: 5252.6406\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2100.8410 - val_loss: 5180.2891\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1731.1111 - val_loss: 5136.2964\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1569.7030 - val_loss: 5053.0913\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1541.4657 - val_loss: 4963.7085\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1640.0384 - val_loss: 4907.6313\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2008.7653 - val_loss: 4933.7949\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1814.4914 - val_loss: 4831.1309\n"
     ]
    }
   ],
   "source": [
    "### 학습률 0.001 지정, 학습률을 지정하지 않았을때와 동일한 값, 기본값 \n",
    "model = Sequential() # 컨테이너 객체 생성\n",
    "# Dense: 전결합층, 1: 뉴런(노드)의 수, input_dim=1: 입력데이터의 가지수\n",
    "# activation='linear': 활성화 함수 입력 -> 출력\n",
    "model.add(Dense(10, input_dim=1, activation='linear'))\n",
    "model.add(Dense(1, activation='linear')) # 입력값은 이전 Layer의 노드수 10개\n",
    "# optimizer='adam': 오차역전파 알고리즘, loss='mse': 평균제곱오차\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='mse')\n",
    "model.summary() # 네트워크 확인, Param: 가중치, 편향, 100만개이상이면 GPU 권장\n",
    "# Dense: 전결합층 기반의 네트워크\n",
    "# Output Shape: (None, 1) 출력은 2차원의 형태임, 컬럼이 1개임\n",
    "# None: 입력값에 따라 출력값의 갯수가 결정된으로 출력값은 가변적임.\n",
    "hist = model.fit(x_train, y_train, validation_split=0.2, shuffle=True,\n",
    "                epochs=300, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "# plt.figure(figsize=(6,4)) # ERROR\n",
    "fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "# 왼쪽 y 축 설정\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 3392220.2500]) # 값을 반영하여 변경 ★\n",
    "\n",
    "# 축 레이블 설정\n",
    "loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "loss_ax.set_ylabel('loss')   # 오차\n",
    "\n",
    "loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "\n",
    "plt.show()\n",
    "# train loss: 하강하면 훈련이 정상적으로 진행되고 있음\n",
    "# val loss: 하강하면 훈련되지 않은 데이터를 대상으로 한 테스트도 정상적으로 진행됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 1364810.0551 - val_loss: 3415696.0000\n",
      "Epoch 2/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 994415.8088 - val_loss: 3412381.5000\n",
      "Epoch 3/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 910157.0643 - val_loss: 3408985.7500\n",
      "Epoch 4/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1145685.7721 - val_loss: 3405244.0000\n",
      "Epoch 5/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 709029.1728 - val_loss: 3402003.2500\n",
      "Epoch 6/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1039267.0037 - val_loss: 3397962.5000\n",
      "Epoch 7/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 685503.0055 - val_loss: 3394591.5000\n",
      "Epoch 8/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1067267.7353 - val_loss: 3390624.5000\n",
      "Epoch 9/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 640650.5671 - val_loss: 3387429.0000\n",
      "Epoch 10/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1029118.8676 - val_loss: 3383445.0000\n",
      "Epoch 11/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1338486.1581 - val_loss: 3379454.7500\n",
      "Epoch 12/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1230749.1140 - val_loss: 3375596.2500\n",
      "Epoch 13/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 791024.4432 - val_loss: 3371930.2500\n",
      "Epoch 14/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 754674.7491 - val_loss: 3368380.0000\n",
      "Epoch 15/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 725593.6371 - val_loss: 3364287.2500\n",
      "Epoch 16/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1011472.8897 - val_loss: 3360151.0000\n",
      "Epoch 17/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 846465.1875 - val_loss: 3356335.7500\n",
      "Epoch 18/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1094408.3888 - val_loss: 3351943.5000\n",
      "Epoch 19/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1224397.9154 - val_loss: 3347823.2500\n",
      "Epoch 20/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 994857.1471 - val_loss: 3343888.0000\n",
      "Epoch 21/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 965983.3961 - val_loss: 3339855.2500\n",
      "Epoch 22/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 800818.6305 - val_loss: 3335934.5000\n",
      "Epoch 23/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1163413.7132 - val_loss: 3331089.2500\n",
      "Epoch 24/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 980491.5836 - val_loss: 3326933.0000\n",
      "Epoch 25/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 898157.3286 - val_loss: 3322802.5000\n",
      "Epoch 26/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 723950.2574 - val_loss: 3318575.0000\n",
      "Epoch 27/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 727616.9320 - val_loss: 3314004.2500\n",
      "Epoch 28/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 824091.6507 - val_loss: 3309462.2500\n",
      "Epoch 29/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 925410.2190 - val_loss: 3304733.5000\n",
      "Epoch 30/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 852264.3971 - val_loss: 3300239.5000\n",
      "Epoch 31/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 849158.7500 - val_loss: 3295357.0000\n",
      "Epoch 32/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 811195.6585 - val_loss: 3290598.0000\n",
      "Epoch 33/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 839373.5809 - val_loss: 3285671.0000\n",
      "Epoch 34/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 868361.8456 - val_loss: 3281002.5000\n",
      "Epoch 35/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 888394.4779 - val_loss: 3275805.5000\n",
      "Epoch 36/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1138436.0993 - val_loss: 3270560.0000\n",
      "Epoch 37/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1010136.1029 - val_loss: 3265661.7500\n",
      "Epoch 38/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 963108.9081 - val_loss: 3260459.5000\n",
      "Epoch 39/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 971774.2610 - val_loss: 3255337.0000\n",
      "Epoch 40/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 955597.1029 - val_loss: 3249875.0000\n",
      "Epoch 41/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 716358.4099 - val_loss: 3244829.7500\n",
      "Epoch 42/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 792385.1471 - val_loss: 3239298.7500\n",
      "Epoch 43/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 875836.8015 - val_loss: 3233646.5000\n",
      "Epoch 44/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1100296.5551 - val_loss: 3227954.5000\n",
      "Epoch 45/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1016804.2169 - val_loss: 3222582.7500\n",
      "Epoch 46/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 774160.1066 - val_loss: 3217252.5000\n",
      "Epoch 47/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1076247.0699 - val_loss: 3210893.5000\n",
      "Epoch 48/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 741195.7863 - val_loss: 3205444.5000\n",
      "Epoch 49/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 892945.4228 - val_loss: 3199780.0000\n",
      "Epoch 50/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1068694.9816 - val_loss: 3193870.2500\n",
      "Epoch 51/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 523736.1806 - val_loss: 3188443.0000\n",
      "Epoch 52/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1133234.8529 - val_loss: 3181583.2500\n",
      "Epoch 53/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 643438.4274 - val_loss: 3175847.2500\n",
      "Epoch 54/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 959085.5294 - val_loss: 3169476.7500\n",
      "Epoch 55/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1092780.2463 - val_loss: 3163106.2500\n",
      "Epoch 56/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 889254.2601 - val_loss: 3156848.5000\n",
      "Epoch 57/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 802770.4881 - val_loss: 3150800.5000\n",
      "Epoch 58/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 960325.7353 - val_loss: 3144275.0000\n",
      "Epoch 59/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 781504.6985 - val_loss: 3137809.5000\n",
      "Epoch 60/300\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 764952.6866 - val_loss: 3131092.5000\n",
      "Epoch 61/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 836707.4007 - val_loss: 3124843.0000\n",
      "Epoch 62/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 860120.6728 - val_loss: 3117720.0000\n",
      "Epoch 63/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 683947.4421 - val_loss: 3111527.5000\n",
      "Epoch 64/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 603890.4586 - val_loss: 3104935.0000\n",
      "Epoch 65/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 832851.1425 - val_loss: 3097603.5000\n",
      "Epoch 66/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1129777.7096 - val_loss: 3090106.0000\n",
      "Epoch 67/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 953785.7169 - val_loss: 3083331.0000\n",
      "Epoch 68/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 535290.3077 - val_loss: 3077098.0000\n",
      "Epoch 69/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 812019.2243 - val_loss: 3069545.2500\n",
      "Epoch 70/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 883084.1654 - val_loss: 3062303.0000\n",
      "Epoch 71/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 889187.0882 - val_loss: 3055386.2500\n",
      "Epoch 72/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 651086.3686 - val_loss: 3048029.5000\n",
      "Epoch 73/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 871286.4957 - val_loss: 3039924.0000\n",
      "Epoch 74/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 942193.9596 - val_loss: 3032300.7500\n",
      "Epoch 75/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 763276.9713 - val_loss: 3025076.5000\n",
      "Epoch 76/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1216587.8456 - val_loss: 3016754.0000\n",
      "Epoch 77/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 643444.5735 - val_loss: 3009928.5000\n",
      "Epoch 78/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 805645.2206 - val_loss: 3002453.7500\n",
      "Epoch 79/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 596010.3879 - val_loss: 2994659.0000\n",
      "Epoch 80/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 702430.3879 - val_loss: 2986479.0000\n",
      "Epoch 81/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1077068.4412 - val_loss: 2978093.5000\n",
      "Epoch 82/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 794704.5478 - val_loss: 2970012.0000\n",
      "Epoch 83/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1012437.3603 - val_loss: 2961749.5000\n",
      "Epoch 84/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 916016.8787 - val_loss: 2953654.5000\n",
      "Epoch 85/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 585061.5811 - val_loss: 2946230.0000\n",
      "Epoch 86/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 690269.0919 - val_loss: 2938212.2500\n",
      "Epoch 87/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 957520.5956 - val_loss: 2928936.5000\n",
      "Epoch 88/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 492750.6490 - val_loss: 2921624.0000\n",
      "Epoch 89/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 736243.5239 - val_loss: 2912343.7500\n",
      "Epoch 90/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 792767.6415 - val_loss: 2903563.7500\n",
      "Epoch 91/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 693244.7988 - val_loss: 2894914.7500\n",
      "Epoch 92/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 480452.0542 - val_loss: 2887123.0000\n",
      "Epoch 93/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 826589.7206 - val_loss: 2877704.5000\n",
      "Epoch 94/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1140048.8566 - val_loss: 2867730.5000\n",
      "Epoch 95/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 893480.2794 - val_loss: 2859292.7500\n",
      "Epoch 96/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 783261.6250 - val_loss: 2851055.5000\n",
      "Epoch 97/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 616550.6636 - val_loss: 2842031.0000\n",
      "Epoch 98/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 854519.7794 - val_loss: 2832519.5000\n",
      "Epoch 99/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 696139.8162 - val_loss: 2823998.0000\n",
      "Epoch 100/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 497476.8290 - val_loss: 2815138.7500\n",
      "Epoch 101/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 853570.3199 - val_loss: 2804950.2500\n",
      "Epoch 102/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 903024.1471 - val_loss: 2795717.5000\n",
      "Epoch 103/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 731972.9467 - val_loss: 2786596.0000\n",
      "Epoch 104/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 695506.5055 - val_loss: 2777256.7500\n",
      "Epoch 105/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 666882.6085 - val_loss: 2767562.2500\n",
      "Epoch 106/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 870255.4228 - val_loss: 2757249.2500\n",
      "Epoch 107/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 644334.8362 - val_loss: 2748424.2500\n",
      "Epoch 108/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 740884.8162 - val_loss: 2738324.2500\n",
      "Epoch 109/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 556252.5951 - val_loss: 2729167.5000\n",
      "Epoch 110/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 769048.9210 - val_loss: 2718720.2500\n",
      "Epoch 111/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 810261.2022 - val_loss: 2708627.5000\n",
      "Epoch 112/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 801774.7096 - val_loss: 2698797.7500\n",
      "Epoch 113/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 538968.3732 - val_loss: 2690238.2500\n",
      "Epoch 114/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 824798.8272 - val_loss: 2679502.0000\n",
      "Epoch 115/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 938972.2353 - val_loss: 2668971.0000\n",
      "Epoch 116/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 770849.3125 - val_loss: 2658852.7500\n",
      "Epoch 117/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 566756.2227 - val_loss: 2649334.2500\n",
      "Epoch 118/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 583749.5993 - val_loss: 2639347.7500\n",
      "Epoch 119/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 838348.3051 - val_loss: 2628257.5000\n",
      "Epoch 120/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 547936.5317 - val_loss: 2618615.0000\n",
      "Epoch 121/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 674284.2346 - val_loss: 2608240.7500\n",
      "Epoch 122/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 729011.0680 - val_loss: 2597775.5000\n",
      "Epoch 123/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 565731.3477 - val_loss: 2587786.5000\n",
      "Epoch 124/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 730800.9449 - val_loss: 2577165.2500\n",
      "Epoch 125/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 779524.5772 - val_loss: 2566245.2500\n",
      "Epoch 126/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 462711.3127 - val_loss: 2556797.5000\n",
      "Epoch 127/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 910098.9007 - val_loss: 2544920.2500\n",
      "Epoch 128/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 734552.1305 - val_loss: 2534631.2500\n",
      "Epoch 129/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 850394.9265 - val_loss: 2523633.0000\n",
      "Epoch 130/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 771093.6397 - val_loss: 2512849.2500\n",
      "Epoch 131/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 753513.7188 - val_loss: 2503000.2500\n",
      "Epoch 132/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 671350.6723 - val_loss: 2491645.7500\n",
      "Epoch 133/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 602004.6765 - val_loss: 2481844.7500\n",
      "Epoch 134/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 495490.9909 - val_loss: 2470810.0000\n",
      "Epoch 135/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 734518.4338 - val_loss: 2459417.5000\n",
      "Epoch 136/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 599943.6471 - val_loss: 2449199.0000\n",
      "Epoch 137/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 723150.3750 - val_loss: 2437327.2500\n",
      "Epoch 138/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 670897.6108 - val_loss: 2426543.2500\n",
      "Epoch 139/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 856269.1434 - val_loss: 2415348.5000\n",
      "Epoch 140/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 689544.6765 - val_loss: 2404542.2500\n",
      "Epoch 141/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 612530.5290 - val_loss: 2393148.2500\n",
      "Epoch 142/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 597966.8563 - val_loss: 2382134.0000\n",
      "Epoch 143/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 615804.2169 - val_loss: 2371558.7500\n",
      "Epoch 144/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 520954.3915 - val_loss: 2360834.5000\n",
      "Epoch 145/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 728588.3713 - val_loss: 2349222.5000\n",
      "Epoch 146/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 496587.7647 - val_loss: 2338703.5000\n",
      "Epoch 147/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 467052.7569 - val_loss: 2327142.5000\n",
      "Epoch 148/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 699890.4338 - val_loss: 2315260.7500\n",
      "Epoch 149/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 678021.5841 - val_loss: 2303452.0000\n",
      "Epoch 150/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 672689.5331 - val_loss: 2292339.7500\n",
      "Epoch 151/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 650551.5386 - val_loss: 2281547.5000\n",
      "Epoch 152/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 571926.6489 - val_loss: 2270612.5000\n",
      "Epoch 153/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 631634.4312 - val_loss: 2258480.5000\n",
      "Epoch 154/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 880802.7757 - val_loss: 2246163.0000\n",
      "Epoch 155/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 576571.3200 - val_loss: 2235719.5000\n",
      "Epoch 156/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 874404.5625 - val_loss: 2223618.5000\n",
      "Epoch 157/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 634664.9301 - val_loss: 2212580.7500\n",
      "Epoch 158/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 500007.6801 - val_loss: 2201575.0000\n",
      "Epoch 159/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 671751.5956 - val_loss: 2189544.2500\n",
      "Epoch 160/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 461048.8824 - val_loss: 2179092.7500\n",
      "Epoch 161/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 674812.5221 - val_loss: 2166715.5000\n",
      "Epoch 162/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 497219.9642 - val_loss: 2155390.5000\n",
      "Epoch 163/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 506836.7877 - val_loss: 2143790.5000\n",
      "Epoch 164/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 438768.6912 - val_loss: 2132659.0000\n",
      "Epoch 165/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 721090.7794 - val_loss: 2120082.7500\n",
      "Epoch 166/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 521971.2960 - val_loss: 2108847.2500\n",
      "Epoch 167/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 673587.6103 - val_loss: 2097279.2500\n",
      "Epoch 168/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 594150.3585 - val_loss: 2085341.0000\n",
      "Epoch 169/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 711589.5588 - val_loss: 2073235.1250\n",
      "Epoch 170/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 449566.6949 - val_loss: 2062900.7500\n",
      "Epoch 171/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 622225.8952 - val_loss: 2050401.2500\n",
      "Epoch 172/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 780847.9136 - val_loss: 2037206.8750\n",
      "Epoch 173/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 646029.6471 - val_loss: 2026579.5000\n",
      "Epoch 174/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 533529.1691 - val_loss: 2015291.0000\n",
      "Epoch 175/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 553050.5901 - val_loss: 2003562.0000\n",
      "Epoch 176/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 508448.6654 - val_loss: 1992573.2500\n",
      "Epoch 177/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 544056.1029 - val_loss: 1979822.2500\n",
      "Epoch 178/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 509868.0496 - val_loss: 1968751.0000\n",
      "Epoch 179/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 550051.0230 - val_loss: 1955868.0000\n",
      "Epoch 180/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 517991.2151 - val_loss: 1944736.2500\n",
      "Epoch 181/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 455177.5037 - val_loss: 1933062.2500\n",
      "Epoch 182/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 573973.2243 - val_loss: 1921151.2500\n",
      "Epoch 183/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 533739.5974 - val_loss: 1908920.2500\n",
      "Epoch 184/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 414681.7845 - val_loss: 1897804.7500\n",
      "Epoch 185/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 509210.1195 - val_loss: 1885288.2500\n",
      "Epoch 186/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 577492.6250 - val_loss: 1872935.7500\n",
      "Epoch 187/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 567739.4871 - val_loss: 1861125.7500\n",
      "Epoch 188/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 319686.3667 - val_loss: 1850575.6250\n",
      "Epoch 189/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 601288.6250 - val_loss: 1837829.3750\n",
      "Epoch 190/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 369572.6095 - val_loss: 1826609.7500\n",
      "Epoch 191/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 423921.5528 - val_loss: 1814413.8750\n",
      "Epoch 192/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 474760.4577 - val_loss: 1801966.5000\n",
      "Epoch 193/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 405323.2340 - val_loss: 1790945.6250\n",
      "Epoch 194/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 375160.8980 - val_loss: 1779753.2500\n",
      "Epoch 195/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 270859.4244 - val_loss: 1768275.2500\n",
      "Epoch 196/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 322321.6893 - val_loss: 1756387.5000\n",
      "Epoch 197/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 346263.1514 - val_loss: 1744510.8750\n",
      "Epoch 198/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 504621.2960 - val_loss: 1731820.5000\n",
      "Epoch 199/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 553740.6746 - val_loss: 1719767.7500\n",
      "Epoch 200/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 640042.1360 - val_loss: 1707132.2500\n",
      "Epoch 201/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 418924.0236 - val_loss: 1695774.0000\n",
      "Epoch 202/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 500398.9044 - val_loss: 1684112.1250\n",
      "Epoch 203/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 489512.9118 - val_loss: 1672082.3750\n",
      "Epoch 204/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 250568.8267 - val_loss: 1662420.7500\n",
      "Epoch 205/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 290385.9447 - val_loss: 1650375.6250\n",
      "Epoch 206/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 438693.6195 - val_loss: 1638734.7500\n",
      "Epoch 207/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 271186.5168 - val_loss: 1627577.0000\n",
      "Epoch 208/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 313144.6706 - val_loss: 1615462.3750\n",
      "Epoch 209/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 473493.1857 - val_loss: 1602885.2500\n",
      "Epoch 210/300\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 403823.8953 - val_loss: 1591528.5000\n",
      "Epoch 211/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 540272.2812 - val_loss: 1579316.7500\n",
      "Epoch 212/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 507264.0790 - val_loss: 1566994.0000\n",
      "Epoch 213/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 517512.3897 - val_loss: 1555506.5000\n",
      "Epoch 214/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 288940.3074 - val_loss: 1545578.5000\n",
      "Epoch 215/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 414662.9816 - val_loss: 1533384.0000\n",
      "Epoch 216/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 409758.6912 - val_loss: 1522115.5000\n",
      "Epoch 217/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 404909.2592 - val_loss: 1510763.7500\n",
      "Epoch 218/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 463857.2849 - val_loss: 1498609.0000\n",
      "Epoch 219/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 484033.0000 - val_loss: 1486683.0000\n",
      "Epoch 220/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 506990.7904 - val_loss: 1475036.7500\n",
      "Epoch 221/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 346574.3197 - val_loss: 1464665.5000\n",
      "Epoch 222/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 329604.5741 - val_loss: 1453509.1250\n",
      "Epoch 223/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 250654.7486 - val_loss: 1443248.0000\n",
      "Epoch 224/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 317920.3048 - val_loss: 1430719.5000\n",
      "Epoch 225/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 400384.9890 - val_loss: 1419011.2500\n",
      "Epoch 226/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 449784.5791 - val_loss: 1407157.8750\n",
      "Epoch 227/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 332123.5076 - val_loss: 1396492.0000\n",
      "Epoch 228/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 390974.2592 - val_loss: 1385257.0000\n",
      "Epoch 229/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 420807.3971 - val_loss: 1373999.7500\n",
      "Epoch 230/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 272485.2538 - val_loss: 1363292.2500\n",
      "Epoch 231/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 368305.2013 - val_loss: 1351707.2500\n",
      "Epoch 232/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 337863.9369 - val_loss: 1340981.5000\n",
      "Epoch 233/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 344840.8722 - val_loss: 1330037.2500\n",
      "Epoch 234/300\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 463061.0312 - val_loss: 1318176.5000\n",
      "Epoch 235/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 354472.1873 - val_loss: 1307477.2500\n",
      "Epoch 236/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 466043.1103 - val_loss: 1295805.0000\n",
      "Epoch 237/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 330404.1935 - val_loss: 1285693.2500\n",
      "Epoch 238/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 365546.5708 - val_loss: 1274863.7500\n",
      "Epoch 239/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 329761.7491 - val_loss: 1263783.1250\n",
      "Epoch 240/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 212787.7025 - val_loss: 1253877.7500\n",
      "Epoch 241/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 473502.6360 - val_loss: 1241580.7500\n",
      "Epoch 242/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 292347.6737 - val_loss: 1231677.3750\n",
      "Epoch 243/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 325762.3989 - val_loss: 1220712.2500\n",
      "Epoch 244/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 246686.2496 - val_loss: 1210790.3750\n",
      "Epoch 245/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 197157.4561 - val_loss: 1200664.7500\n",
      "Epoch 246/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 286531.0115 - val_loss: 1189556.6250\n",
      "Epoch 247/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 227292.0414 - val_loss: 1179359.1250\n",
      "Epoch 248/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 317966.1296 - val_loss: 1168108.0000\n",
      "Epoch 249/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 296490.5653 - val_loss: 1157104.5000\n",
      "Epoch 250/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 344399.1232 - val_loss: 1146404.2500\n",
      "Epoch 251/300\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 370807.1535 - val_loss: 1136056.5000\n",
      "Epoch 252/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 307116.8061 - val_loss: 1125752.1250\n",
      "Epoch 253/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 220382.1319 - val_loss: 1116058.8750\n",
      "Epoch 254/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 298138.3952 - val_loss: 1105104.5000\n",
      "Epoch 255/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 246242.0069 - val_loss: 1094688.7500\n",
      "Epoch 256/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 409299.5257 - val_loss: 1083488.5000\n",
      "Epoch 257/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 300470.3428 - val_loss: 1073911.0000\n",
      "Epoch 258/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 215732.1994 - val_loss: 1064660.0000\n",
      "Epoch 259/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 263706.0046 - val_loss: 1053593.0000\n",
      "Epoch 260/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 388267.0184 - val_loss: 1043514.0000\n",
      "Epoch 261/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 356981.9779 - val_loss: 1033238.7500\n",
      "Epoch 262/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 246223.6893 - val_loss: 1023730.5000\n",
      "Epoch 263/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 328150.5294 - val_loss: 1013351.6250\n",
      "Epoch 264/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 276575.7822 - val_loss: 1003708.3750\n",
      "Epoch 265/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 292636.5744 - val_loss: 993806.6875\n",
      "Epoch 266/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 278523.1222 - val_loss: 984169.2500\n",
      "Epoch 267/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 287718.5680 - val_loss: 974392.5625\n",
      "Epoch 268/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 296451.9926 - val_loss: 964078.6875\n",
      "Epoch 269/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 228861.6190 - val_loss: 954777.8750\n",
      "Epoch 270/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 282596.6719 - val_loss: 945194.2500\n",
      "Epoch 271/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 247615.0340 - val_loss: 935467.6250\n",
      "Epoch 272/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 322657.5551 - val_loss: 925828.8750\n",
      "Epoch 273/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 219900.5456 - val_loss: 916265.6250\n",
      "Epoch 274/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 257483.0064 - val_loss: 906871.8750\n",
      "Epoch 275/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 278055.5184 - val_loss: 897332.6250\n",
      "Epoch 276/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 181795.1739 - val_loss: 888575.3750\n",
      "Epoch 277/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 203813.2911 - val_loss: 878830.0000\n",
      "Epoch 278/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 149957.1700 - val_loss: 870707.5000\n",
      "Epoch 279/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 185282.2335 - val_loss: 861297.3125\n",
      "Epoch 280/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 157605.1868 - val_loss: 851753.0625\n",
      "Epoch 281/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 221746.9393 - val_loss: 842335.6250\n",
      "Epoch 282/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 208133.1268 - val_loss: 833325.3750\n",
      "Epoch 283/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 191513.6348 - val_loss: 823700.9375\n",
      "Epoch 284/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 205793.3235 - val_loss: 815030.1250\n",
      "Epoch 285/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 233124.6333 - val_loss: 806271.9375\n",
      "Epoch 286/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 170720.6548 - val_loss: 796908.9375\n",
      "Epoch 287/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 168379.5175 - val_loss: 788435.3750\n",
      "Epoch 288/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step - loss: 191244.8428 - val_loss: 779386.8125\n",
      "Epoch 289/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 208112.9010 - val_loss: 770253.6875\n",
      "Epoch 290/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 155297.9168 - val_loss: 762149.0625\n",
      "Epoch 291/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 171411.5094 - val_loss: 753191.9375\n",
      "Epoch 292/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 197380.4072 - val_loss: 744242.5000\n",
      "Epoch 293/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 270925.7748 - val_loss: 735213.2500\n",
      "Epoch 294/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 167353.5975 - val_loss: 727500.3750\n",
      "Epoch 295/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 155844.6425 - val_loss: 719529.5625\n",
      "Epoch 296/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 148584.6464 - val_loss: 711006.3750\n",
      "Epoch 297/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 116821.4983 - val_loss: 702964.2500\n",
      "Epoch 298/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 147417.8699 - val_loss: 694833.0625\n",
      "Epoch 299/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 137270.5588 - val_loss: 687013.8125\n",
      "Epoch 300/300\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 183278.5754 - val_loss: 677742.0000\n"
     ]
    }
   ],
   "source": [
    "### 학습률 0.0005 지정\n",
    "model = Sequential() # 컨테이너 객체 생성\n",
    "# Dense: 전결합층, 1: 뉴런(노드)의 수, input_dim=1: 입력데이터의 가지수\n",
    "# activation='linear': 활성화 함수 입력 -> 출력\n",
    "model.add(Dense(10, input_dim=1, activation='linear'))\n",
    "model.add(Dense(1, activation='linear')) # 입력값은 이전 Layer의 노드수 10개\n",
    "# optimizer='adam': 오차역전파 알고리즘, loss='mse': 평균제곱오차\n",
    "model.compile(optimizer=Adam(lr=0.0005), loss='mse')\n",
    "model.summary() # 네트워크 확인, Param: 가중치, 편향, 100만개이상이면 GPU 권장\n",
    "# Dense: 전결합층 기반의 네트워크\n",
    "# Output Shape: (None, 1) 출력은 2차원의 형태임, 컬럼이 1개임\n",
    "# None: 입력값에 따라 출력값의 갯수가 결정된으로 출력값은 가변적임.\n",
    "hist = model.fit(x_train, y_train, validation_split=0.2, shuffle=True,\n",
    "                epochs=300, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "# plt.figure(figsize=(6,4)) # ERROR\n",
    "fig.set_size_inches(10, 5)  # 챠트 크기 설정\n",
    "\n",
    "# 왼쪽 y 축 설정\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_ylim([0.0, 3392220.2500]) # 값을 반영하여 변경 ★\n",
    "\n",
    "# 축 레이블 설정\n",
    "loss_ax.set_xlabel('epoch')  # 학습 횟수\n",
    "loss_ax.set_ylabel('loss')   # 오차\n",
    "\n",
    "loss_ax.legend(loc='upper left') # 오차 레이블 위치\n",
    "\n",
    "plt.show()\n",
    "# train loss: 하강하면 훈련이 정상적으로 진행되고 있음\n",
    "# val loss: 하강하면 훈련되지 않은 데이터를 대상으로 한 테스트도 정상적으로 진행됨."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}